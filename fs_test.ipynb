{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# The train split of client 1\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m train_data_client1 \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./data/CIKM22Competition/13/train.pt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Check the first sample\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(train_data_client1[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m~/.conda/envs/FederatedScope_thesis/lib/python3.9/site-packages/torch/serialization.py:607\u001B[0m, in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    605\u001B[0m             opened_file\u001B[38;5;241m.\u001B[39mseek(orig_position)\n\u001B[1;32m    606\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mload(opened_file)\n\u001B[0;32m--> 607\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mopened_zipfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpickle_module\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpickle_load_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n",
      "File \u001B[0;32m~/.conda/envs/FederatedScope_thesis/lib/python3.9/site-packages/torch/serialization.py:882\u001B[0m, in \u001B[0;36m_load\u001B[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001B[0m\n\u001B[1;32m    880\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[1;32m    881\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[0;32m--> 882\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    884\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[1;32m    886\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/.conda/envs/FederatedScope_thesis/lib/python3.9/site-packages/torch/serialization.py:857\u001B[0m, in \u001B[0;36m_load.<locals>.persistent_load\u001B[0;34m(saved_id)\u001B[0m\n\u001B[1;32m    855\u001B[0m data_type, key, location, size \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m    856\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m loaded_storages:\n\u001B[0;32m--> 857\u001B[0m     \u001B[43mload_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_maybe_decode_ascii\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocation\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    858\u001B[0m storage \u001B[38;5;241m=\u001B[39m loaded_storages[key]\n\u001B[1;32m    859\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m storage\n",
      "File \u001B[0;32m~/.conda/envs/FederatedScope_thesis/lib/python3.9/site-packages/torch/serialization.py:845\u001B[0m, in \u001B[0;36m_load.<locals>.load_tensor\u001B[0;34m(data_type, size, key, location)\u001B[0m\n\u001B[1;32m    842\u001B[0m name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    843\u001B[0m dtype \u001B[38;5;241m=\u001B[39m data_type(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mdtype\n\u001B[0;32m--> 845\u001B[0m storage \u001B[38;5;241m=\u001B[39m \u001B[43mzip_file\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_storage_from_record\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mstorage()\n\u001B[1;32m    846\u001B[0m loaded_storages[key] \u001B[38;5;241m=\u001B[39m restore_location(storage, location)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# The train split of client 1\n",
    "train_data_client1 = torch.load('./data/CIKM22Competition/13/train.pt')\n",
    "# Check the first sample\n",
    "print(train_data_client1[0])\n",
    "# Check the label of the first sample\n",
    "print(len(train_data_client1))\n",
    "# Check the index of the first sample as ${sample_id}\n",
    "print(train_data_client1[0].data_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1: 1249\n",
    "2: 181\n",
    "3: 2219\n",
    "4: 101\n",
    "5: 188\n",
    "6: 1101\n",
    "7: 2228\n",
    "8: 777\n",
    "9: 134706\n",
    "10: 109392\n",
    "11: 2268\n",
    "12: 608\n",
    "13: 70648"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = [1249, 181, 2219, 101, 188, 1101, 2228, 777, 134706, 109392, 2268, 608, 70648]\n",
    "a/np.array(sum(a))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python federatedscope/main.py --cfg federatedscope/gfl/baseline/isolated_gin_minibatch_on_cikmcup.yaml --client_cfg federatedscope/gfl/baseline/isolated_gin_minibatch_on_cikmcup_per_client.yaml federate.total_round_num 3\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del train_data_client1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-06 15:48:46,102 (utils:129)INFO: the current machine is at 127.0.1.1\r\n",
      "2022-09-06 15:48:46,102 (utils:131)INFO: the current dir is /home/michael/Master thesis/Code/FederatedScope_thesis\r\n",
      "2022-09-06 15:48:46,102 (utils:132)INFO: the output dir is exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "2022-09-06 15:48:46,153 (cikm_cup:57)INFO: Loading CIKMCUP data from /home/michael/Master thesis/Code/FederatedScope_thesis/data/CIKM22Competition.\r\n",
      "2022-09-06 15:48:46,153 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #1.\r\n",
      "2022-09-06 15:48:46,351 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #2.\r\n",
      "2022-09-06 15:48:46,365 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #3.\r\n",
      "2022-09-06 15:48:46,619 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #4.\r\n",
      "2022-09-06 15:48:46,627 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #5.\r\n",
      "2022-09-06 15:48:46,644 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #6.\r\n",
      "2022-09-06 15:48:46,784 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #7.\r\n",
      "2022-09-06 15:48:47,053 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #8.\r\n",
      "2022-09-06 15:48:47,138 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #9.\r\n",
      "2022-09-06 15:49:10,000 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #10.\r\n",
      "2022-09-06 15:49:30,547 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #11.\r\n",
      "2022-09-06 15:49:30,767 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #12.\r\n",
      "2022-09-06 15:49:30,821 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #13.\r\n",
      "2022-09-06 15:49:45,444 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: MSELoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.0\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 1\r\n",
      "  task: graph\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,472 (fed_runner:249)INFO: Server #0 has been set up ... \r\n",
      "2022-09-06 15:49:45,481 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.263789\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,488 (fed_runner:302)INFO: Client 1 has been set up ... \r\n",
      "2022-09-06 15:49:45,498 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.289617\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.01\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,504 (fed_runner:302)INFO: Client 2 has been set up ... \r\n",
      "2022-09-06 15:49:45,513 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.355404\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.001\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,522 (fed_runner:302)INFO: Client 3 has been set up ... \r\n",
      "2022-09-06 15:49:45,531 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.176471\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.01\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,536 (fed_runner:302)INFO: Client 4 has been set up ... \r\n",
      "2022-09-06 15:49:45,546 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.396825\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.0001\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,552 (fed_runner:302)INFO: Client 5 has been set up ... \r\n",
      "2022-09-06 15:49:45,561 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.26158\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.0005\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,567 (fed_runner:302)INFO: Client 6 has been set up ... \r\n",
      "2022-09-06 15:49:45,577 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.302378\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.01\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,585 (fed_runner:302)INFO: Client 7 has been set up ... \r\n",
      "2022-09-06 15:49:45,595 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.211538\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.05\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,601 (fed_runner:302)INFO: Client 8 has been set up ... \r\n",
      "2022-09-06 15:49:45,611 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: MSELoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.059199\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 1\r\n",
      "  task: graphRegression\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,622 (fed_runner:302)INFO: Client 9 has been set up ... \r\n",
      "2022-09-06 15:49:45,632 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: MSELoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.007083\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 10\r\n",
      "  task: graphRegression\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.05\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,639 (fed_runner:302)INFO: Client 10 has been set up ... \r\n",
      "2022-09-06 15:49:45,649 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: MSELoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.734011\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 1\r\n",
      "  task: graphRegression\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.05\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,656 (fed_runner:302)INFO: Client 11 has been set up ... \r\n",
      "2022-09-06 15:49:45,665 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: MSELoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 1.361326\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 1\r\n",
      "  task: graphRegression\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.01\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,671 (fed_runner:302)INFO: Client 12 has been set up ... \r\n",
      "2022-09-06 15:49:45,681 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: MSELoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.004389\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 50\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 10\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.5\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 12\r\n",
      "  task: graphRegression\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.05\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-06 15:49:45,688 (fed_runner:302)INFO: Client 13 has been set up ... \r\n",
      "2022-09-06 15:49:45,688 (trainer:323)INFO: Model meta-info: <class 'federatedscope.gfl.model.graph_level.GNN_Net_Graph'>.\r\n",
      "2022-09-06 15:49:45,689 (trainer:331)INFO: Num of original para names: 58.\r\n",
      "2022-09-06 15:49:45,689 (trainer:332)INFO: Num of original trainable para names: 44.\r\n",
      "2022-09-06 15:49:45,689 (trainer:334)INFO: Num of preserved para names in local update: 32. \r\n",
      "Preserved para names in local update: {'gnn.convs.0.nn.linears.0.bias', 'gnn.convs.0.nn.norms.1.num_batches_tracked', 'gnn.convs.0.nn.norms.1.running_mean', 'gnn.convs.1.nn.linears.1.bias', 'gnn.convs.1.nn.linears.1.weight', 'gnn.convs.0.nn.norms.0.running_var', 'gnn.convs.0.nn.norms.0.num_batches_tracked', 'gnn.convs.1.nn.linears.0.bias', 'gnn.convs.0.nn.linears.1.weight', 'gnn.convs.0.nn.norms.1.weight', 'gnn.convs.1.nn.norms.1.weight', 'linear.0.weight', 'gnn.convs.1.nn.norms.0.weight', 'gnn.convs.0.nn.linears.1.bias', 'gnn.convs.0.nn.linears.0.weight', 'gnn.convs.0.nn.norms.0.running_mean', 'gnn.convs.0.eps', 'gnn.convs.1.nn.norms.0.bias', 'gnn.convs.1.eps', 'gnn.convs.0.nn.norms.0.weight', 'gnn.convs.1.nn.norms.1.running_mean', 'gnn.convs.1.nn.norms.0.num_batches_tracked', 'gnn.convs.1.nn.norms.1.running_var', 'gnn.convs.0.nn.norms.1.bias', 'gnn.convs.0.nn.norms.1.running_var', 'gnn.convs.1.nn.norms.1.num_batches_tracked', 'gnn.convs.1.nn.norms.0.running_mean', 'gnn.convs.0.nn.norms.0.bias', 'gnn.convs.1.nn.linears.0.weight', 'gnn.convs.1.nn.norms.0.running_var', 'gnn.convs.1.nn.norms.1.bias', 'linear.0.bias'}.\r\n",
      "2022-09-06 15:49:45,689 (trainer:338)INFO: Num of filtered para names in local update: 26. \r\n",
      "Filtered para names in local update: {'encoder_atom.atom_embedding_list.0.weight', 'encoder_atom.atom_embedding_list.13.weight', 'encoder_atom.atom_embedding_list.15.weight', 'encoder_atom.atom_embedding_list.10.weight', 'encoder_atom.atom_embedding_list.3.weight', 'encoder_atom.atom_embedding_list.18.weight', 'clf.weight', 'encoder_atom.atom_embedding_list.21.weight', 'encoder_atom.atom_embedding_list.9.weight', 'encoder_atom.atom_embedding_list.16.weight', 'encoder_atom.atom_embedding_list.19.weight', 'encoder_atom.atom_embedding_list.7.weight', 'encoder_atom.atom_embedding_list.5.weight', 'encoder_atom.atom_embedding_list.4.weight', 'encoder_atom.atom_embedding_list.11.weight', 'encoder_atom.atom_embedding_list.20.weight', 'encoder.bias', 'encoder_atom.atom_embedding_list.6.weight', 'encoder_atom.atom_embedding_list.8.weight', 'encoder_atom.atom_embedding_list.2.weight', 'encoder_atom.atom_embedding_list.1.weight', 'encoder.weight', 'encoder_atom.atom_embedding_list.17.weight', 'clf.bias', 'encoder_atom.atom_embedding_list.12.weight', 'encoder_atom.atom_embedding_list.14.weight'}.\r\n",
      "2022-09-06 15:49:45,689 (trainer:343)INFO: After register default hooks,\r\n",
      "\tthe hooks_in_train is:\r\n",
      "\t{\r\n",
      "\t  \"on_fit_start\": [\r\n",
      "\t    \"_hook_on_fit_start_init\",\r\n",
      "\t    \"_hook_on_fit_start_calculate_model_size\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_epoch_start\": [\r\n",
      "\t    \"_hook_on_epoch_start\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_start\": [\r\n",
      "\t    \"_hook_on_batch_start_init\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_forward\": [\r\n",
      "\t    \"_hook_on_batch_forward\",\r\n",
      "\t    \"_hook_on_batch_forward_regularizer\",\r\n",
      "\t    \"_hook_on_batch_forward_flop_count\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_backward\": [\r\n",
      "\t    \"_hook_on_batch_backward\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_end\": [\r\n",
      "\t    \"_hook_on_batch_end\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_fit_end\": [\r\n",
      "\t    \"_hook_on_fit_end\"\r\n",
      "\t  ]\r\n",
      "\t};\r\n",
      "\tthe hooks_in_eval is:\r\n",
      "            t{\r\n",
      "\t  \"on_fit_start\": [\r\n",
      "\t    \"_hook_on_fit_start_init\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_epoch_start\": [\r\n",
      "\t    \"_hook_on_epoch_start\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_start\": [\r\n",
      "\t    \"_hook_on_batch_start_init\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_forward\": [\r\n",
      "\t    \"_hook_on_batch_forward\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_end\": [\r\n",
      "\t    \"_hook_on_batch_end\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_fit_end\": [\r\n",
      "\t    \"_hook_on_fit_end\"\r\n",
      "\t  ]\r\n",
      "\t}\r\n",
      "2022-09-06 15:49:45,692 (server:637)INFO: ----------- Starting training (Round #0) -------------\r\n",
      "2022-09-06 15:49:46,208 (client:259)INFO: {'Role': 'Client #7', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.693071, 'train_total': 2228, 'train_imp_ratio': -58.824831, 'train_loss': 1544.1628}}\r\n",
      "2022-09-06 15:49:46,320 (client:259)INFO: {'Role': 'Client #12', 'Round': 0, 'Results_raw': {'train_avg_loss': 13.370018, 'train_total': 608, 'train_imp_ratio': -882.131981, 'train_loss': 8128.9711}}\r\n",
      "2022-09-06 15:49:46,359 (client:259)INFO: {'Role': 'Client #5', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.694398, 'train_total': 188, 'train_imp_ratio': -36.723541, 'train_loss': 130.546798}}\r\n",
      "2022-09-06 15:49:46,879 (client:259)INFO: {'Role': 'Client #11', 'Round': 0, 'Results_raw': {'train_avg_loss': 2.693198, 'train_total': 2268, 'train_imp_ratio': -266.91527, 'train_loss': 6108.174134}}\r\n",
      "2022-09-06 15:49:47,389 (client:259)INFO: {'Role': 'Client #3', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.702292, 'train_total': 2219, 'train_imp_ratio': -49.62439, 'train_loss': 1558.385796}}\r\n",
      "2022-09-06 15:50:15,922 (client:259)INFO: {'Role': 'Client #9', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.066967, 'train_total': 134706, 'train_imp_ratio': -13.122666, 'train_loss': 9020.923583}}\r\n",
      "2022-09-06 15:50:15,959 (client:259)INFO: {'Role': 'Client #2', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.676545, 'train_total': 181, 'train_imp_ratio': -41.16567, 'train_loss': 122.454682}}\r\n",
      "2022-09-06 15:50:16,098 (client:259)INFO: {'Role': 'Client #8', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.539045, 'train_total': 777, 'train_imp_ratio': 22.124552, 'train_loss': 418.838072}}\r\n",
      "2022-09-06 15:50:35,432 (client:259)INFO: {'Role': 'Client #10', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.013182, 'train_total': 109392, 'train_imp_ratio': -86.10535, 'train_loss': 1441.988306}}\r\n",
      "2022-09-06 15:50:35,457 (client:259)INFO: {'Role': 'Client #4', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.676613, 'train_total': 101, 'train_imp_ratio': -124.421919, 'train_loss': 68.337959}}\r\n",
      "2022-09-06 15:50:35,727 (client:259)INFO: {'Role': 'Client #1', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.648064, 'train_total': 1249, 'train_imp_ratio': -46.294473, 'train_loss': 809.431516}}\r\n",
      "2022-09-06 15:50:35,958 (client:259)INFO: {'Role': 'Client #6', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.703441, 'train_total': 1101, 'train_imp_ratio': -126.041996, 'train_loss': 774.487996}}\r\n",
      "2022-09-06 15:50:51,320 (client:259)INFO: {'Role': 'Client #13', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.01557, 'train_total': 70648, 'train_imp_ratio': -254.756641, 'train_loss': 1100.008689}}\r\n",
      "2022-09-06 15:50:51,327 (server:323)INFO: ----------- Starting a new training round (Round #1) -------------\r\n",
      "2022-09-06 15:50:51,581 (client:259)INFO: {'Role': 'Client #6', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.694871, 'train_total': 1101, 'train_imp_ratio': -97.916955, 'train_loss': 765.052537}}\r\n",
      "2022-09-06 15:50:52,110 (client:259)INFO: {'Role': 'Client #3', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.697311, 'train_total': 2219, 'train_imp_ratio': -50.765593, 'train_loss': 1547.333056}}\r\n",
      "2022-09-06 15:50:52,136 (client:259)INFO: {'Role': 'Client #4', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.67129, 'train_total': 101, 'train_imp_ratio': -96.369179, 'train_loss': 67.800262}}\r\n",
      "2022-09-06 15:50:52,176 (client:259)INFO: {'Role': 'Client #5', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.692163, 'train_total': 188, 'train_imp_ratio': -9.915004, 'train_loss': 130.126596}}\r\n",
      "2022-09-06 15:50:52,291 (client:259)INFO: {'Role': 'Client #12', 'Round': 1, 'Results_raw': {'train_avg_loss': 12.845118, 'train_total': 608, 'train_imp_ratio': -843.573954, 'train_loss': 7809.832001}}\r\n",
      "2022-09-06 15:50:52,598 (client:259)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.647284, 'train_total': 1249, 'train_imp_ratio': -43.866349, 'train_loss': 808.457653}}\r\n",
      "2022-09-06 15:51:11,787 (client:259)INFO: {'Role': 'Client #10', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.009425, 'train_total': 109392, 'train_imp_ratio': -33.0658, 'train_loss': 1031.025239}}\r\n",
      "2022-09-06 15:51:26,055 (client:259)INFO: {'Role': 'Client #13', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.007676, 'train_total': 70648, 'train_imp_ratio': -74.898475, 'train_loss': 542.314819}}\r\n",
      "2022-09-06 15:51:26,205 (client:259)INFO: {'Role': 'Client #8', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.508233, 'train_total': 777, 'train_imp_ratio': 21.51615, 'train_loss': 394.896773}}\r\n",
      "2022-09-06 15:51:26,722 (client:259)INFO: {'Role': 'Client #7', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.688646, 'train_total': 2228, 'train_imp_ratio': -49.621897, 'train_loss': 1534.304255}}\r\n",
      "2022-09-06 15:51:26,761 (client:259)INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.678384, 'train_total': 181, 'train_imp_ratio': -41.16567, 'train_loss': 122.787526}}\r\n",
      "2022-09-06 15:51:27,292 (client:259)INFO: {'Role': 'Client #11', 'Round': 1, 'Results_raw': {'train_avg_loss': 2.018982, 'train_total': 2268, 'train_imp_ratio': -175.061536, 'train_loss': 4579.051049}}\r\n",
      "2022-09-06 15:51:56,468 (client:259)INFO: {'Role': 'Client #9', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.057131, 'train_total': 134706, 'train_imp_ratio': 3.49324, 'train_loss': 7695.893632}}\r\n",
      "2022-09-06 15:51:56,476 (server:323)INFO: ----------- Starting a new training round (Round #2) -------------\r\n",
      "2022-09-06 15:51:57,010 (client:259)INFO: {'Role': 'Client #11', 'Round': 2, 'Results_raw': {'train_avg_loss': 1.758721, 'train_total': 2268, 'train_imp_ratio': -139.604174, 'train_loss': 3988.77936}}\r\n",
      "2022-09-06 15:51:57,058 (client:259)INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.68, 'train_total': 181, 'train_imp_ratio': -41.16567, 'train_loss': 123.079921}}\r\n",
      "2022-09-06 15:51:57,586 (client:259)INFO: {'Role': 'Client #7', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.686588, 'train_total': 2228, 'train_imp_ratio': -48.285987, 'train_loss': 1529.718726}}\r\n",
      "2022-09-06 15:51:57,732 (client:259)INFO: {'Role': 'Client #8', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.476623, 'train_total': 777, 'train_imp_ratio': 21.51615, 'train_loss': 370.335703}}\r\n",
      "2022-09-06 15:51:58,259 (client:259)INFO: {'Role': 'Client #3', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.698991, 'train_total': 2219, 'train_imp_ratio': -53.047999, 'train_loss': 1551.061058}}\r\n",
      "2022-09-06 15:52:12,312 (client:259)INFO: {'Role': 'Client #13', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.006918, 'train_total': 70648, 'train_imp_ratio': -57.628404, 'train_loss': 488.764794}}\r\n",
      "2022-09-06 15:52:12,556 (client:259)INFO: {'Role': 'Client #6', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.688918, 'train_total': 1101, 'train_imp_ratio': -48.611328, 'train_loss': 758.498998}}\r\n",
      "2022-09-06 15:52:12,667 (client:259)INFO: {'Role': 'Client #12', 'Round': 2, 'Results_raw': {'train_avg_loss': 12.346458, 'train_total': 608, 'train_imp_ratio': -806.943486, 'train_loss': 7506.64621}}\r\n",
      "2022-09-06 15:52:12,977 (client:259)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.650024, 'train_total': 1249, 'train_imp_ratio': -45.990957, 'train_loss': 811.880391}}\r\n",
      "2022-09-06 15:52:13,003 (client:259)INFO: {'Role': 'Client #4', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.671944, 'train_total': 101, 'train_imp_ratio': -96.369179, 'train_loss': 67.866373}}\r\n",
      "2022-09-06 15:52:13,044 (client:259)INFO: {'Role': 'Client #5', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.689932, 'train_total': 188, 'train_imp_ratio': -15.276711, 'train_loss': 129.707286}}\r\n",
      "2022-09-06 15:52:32,075 (client:259)INFO: {'Role': 'Client #10', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.008968, 'train_total': 109392, 'train_imp_ratio': -26.611667, 'train_loss': 981.017074}}\r\n",
      "2022-09-06 15:53:02,126 (client:259)INFO: {'Role': 'Client #9', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.055564, 'train_total': 134706, 'train_imp_ratio': 6.139996, 'train_loss': 7484.82851}}\r\n",
      "2022-09-06 15:53:02,141 (server:323)INFO: ----------- Starting a new training round (Round #3) -------------\r\n",
      "2022-09-06 15:53:02,401 (client:259)INFO: {'Role': 'Client #6', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.683056, 'train_total': 1101, 'train_imp_ratio': -20.83351, 'train_loss': 752.044616}}\r\n",
      "2022-09-06 15:53:02,440 (client:259)INFO: {'Role': 'Client #5', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.688055, 'train_total': 188, 'train_imp_ratio': -13.936284, 'train_loss': 129.354383}}\r\n",
      "2022-09-06 15:53:02,952 (client:259)INFO: {'Role': 'Client #3', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.697607, 'train_total': 2219, 'train_imp_ratio': -48.863588, 'train_loss': 1547.989741}}\r\n",
      "2022-09-06 15:53:03,505 (client:259)INFO: {'Role': 'Client #11', 'Round': 3, 'Results_raw': {'train_avg_loss': 1.561978, 'train_total': 2268, 'train_imp_ratio': -112.800383, 'train_loss': 3542.566731}}\r\n",
      "2022-09-06 15:53:34,146 (client:259)INFO: {'Role': 'Client #9', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.054551, 'train_total': 134706, 'train_imp_ratio': 7.852217, 'train_loss': 7348.288154}}\r\n",
      "2022-09-06 15:53:34,670 (client:259)INFO: {'Role': 'Client #7', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.687247, 'train_total': 2228, 'train_imp_ratio': -47.543815, 'train_loss': 1531.186436}}\r\n",
      "2022-09-06 15:53:53,677 (client:259)INFO: {'Role': 'Client #10', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.008771, 'train_total': 109392, 'train_imp_ratio': -23.827521, 'train_loss': 959.444888}}\r\n",
      "2022-09-06 15:53:53,715 (client:259)INFO: {'Role': 'Client #2', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.679669, 'train_total': 181, 'train_imp_ratio': -41.16567, 'train_loss': 123.019999}}\r\n",
      "2022-09-06 15:53:54,010 (client:259)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.648438, 'train_total': 1249, 'train_imp_ratio': -46.597988, 'train_loss': 809.899076}}\r\n",
      "2022-09-06 15:53:54,157 (client:259)INFO: {'Role': 'Client #8', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.460171, 'train_total': 777, 'train_imp_ratio': 21.51615, 'train_loss': 357.552901}}\r\n",
      "2022-09-06 15:53:54,267 (client:259)INFO: {'Role': 'Client #12', 'Round': 3, 'Results_raw': {'train_avg_loss': 11.843357, 'train_total': 608, 'train_imp_ratio': -769.986913, 'train_loss': 7200.761322}}\r\n",
      "2022-09-06 15:54:08,009 (client:259)INFO: {'Role': 'Client #13', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.00662, 'train_total': 70648, 'train_imp_ratio': -50.834428, 'train_loss': 467.698413}}\r\n",
      "2022-09-06 15:54:08,033 (client:259)INFO: {'Role': 'Client #4', 'Round': 3, 'Results_raw': {'train_avg_loss': 0.672137, 'train_total': 101, 'train_imp_ratio': -96.369179, 'train_loss': 67.885842}}\r\n",
      "2022-09-06 15:54:08,040 (server:323)INFO: ----------- Starting a new training round (Round #4) -------------\r\n",
      "2022-09-06 15:54:08,144 (client:259)INFO: {'Role': 'Client #12', 'Round': 4, 'Results_raw': {'train_avg_loss': 11.383352, 'train_total': 608, 'train_imp_ratio': -736.195906, 'train_loss': 6921.078064}}\r\n",
      "2022-09-06 15:54:34,639 (client:259)INFO: {'Role': 'Client #9', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.054023, 'train_total': 134706, 'train_imp_ratio': 8.74371, 'train_loss': 7277.197035}}\r\n",
      "2022-09-06 15:54:34,675 (client:259)INFO: {'Role': 'Client #2', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.679516, 'train_total': 181, 'train_imp_ratio': -41.16567, 'train_loss': 122.992328}}\r\n",
      "2022-09-06 15:54:34,896 (client:259)INFO: {'Role': 'Client #6', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.681836, 'train_total': 1101, 'train_imp_ratio': -19.097396, 'train_loss': 750.701546}}\r\n",
      "2022-09-06 15:54:35,358 (client:259)INFO: {'Role': 'Client #7', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.684368, 'train_total': 2228, 'train_imp_ratio': -47.246946, 'train_loss': 1524.772434}}\r\n",
      "2022-09-06 15:54:35,394 (client:259)INFO: {'Role': 'Client #5', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.685195, 'train_total': 188, 'train_imp_ratio': -5.893723, 'train_loss': 128.816606}}\r\n",
      "2022-09-06 15:54:52,313 (client:259)INFO: {'Role': 'Client #10', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.008661, 'train_total': 109392, 'train_imp_ratio': -22.282536, 'train_loss': 947.473559}}\r\n",
      "2022-09-06 15:54:52,583 (client:259)INFO: {'Role': 'Client #1', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.649487, 'train_total': 1249, 'train_imp_ratio': -47.205019, 'train_loss': 811.209736}}\r\n",
      "2022-09-06 15:54:53,069 (client:259)INFO: {'Role': 'Client #11', 'Round': 4, 'Results_raw': {'train_avg_loss': 1.514434, 'train_total': 2268, 'train_imp_ratio': -106.323096, 'train_loss': 3434.736762}}\r\n",
      "2022-09-06 15:55:05,685 (client:259)INFO: {'Role': 'Client #13', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.006428, 'train_total': 70648, 'train_imp_ratio': -46.448512, 'train_loss': 454.09892}}\r\n",
      "2022-09-06 15:55:06,147 (client:259)INFO: {'Role': 'Client #3', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.69659, 'train_total': 2219, 'train_imp_ratio': -50.892394, 'train_loss': 1545.732917}}\r\n",
      "2022-09-06 15:55:06,171 (client:259)INFO: {'Role': 'Client #4', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.672036, 'train_total': 101, 'train_imp_ratio': -96.369179, 'train_loss': 67.875612}}\r\n",
      "2022-09-06 15:55:06,304 (client:259)INFO: {'Role': 'Client #8', 'Round': 4, 'Results_raw': {'train_avg_loss': 0.454259, 'train_total': 777, 'train_imp_ratio': 21.51615, 'train_loss': 352.95918}}\r\n",
      "2022-09-06 15:55:06,311 (server:323)INFO: ----------- Starting a new training round (Round #5) -------------\r\n",
      "2022-09-06 15:55:06,536 (client:259)INFO: {'Role': 'Client #6', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.67827, 'train_total': 1101, 'train_imp_ratio': -10.76405, 'train_loss': 746.775602}}\r\n",
      "2022-09-06 15:55:06,802 (client:259)INFO: {'Role': 'Client #1', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.644322, 'train_total': 1249, 'train_imp_ratio': -47.205019, 'train_loss': 804.758477}}\r\n",
      "2022-09-06 15:55:19,315 (client:259)INFO: {'Role': 'Client #13', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.006246, 'train_total': 70648, 'train_imp_ratio': -42.308604, 'train_loss': 441.262084}}\r\n",
      "2022-09-06 15:55:19,786 (client:259)INFO: {'Role': 'Client #3', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.697457, 'train_total': 2219, 'train_imp_ratio': -54.950004, 'train_loss': 1547.656932}}\r\n",
      "2022-09-06 15:55:19,810 (client:259)INFO: {'Role': 'Client #4', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.670181, 'train_total': 101, 'train_imp_ratio': -96.369179, 'train_loss': 67.688286}}\r\n",
      "2022-09-06 15:55:20,289 (client:259)INFO: {'Role': 'Client #7', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.684465, 'train_total': 2228, 'train_imp_ratio': -47.246946, 'train_loss': 1524.988906}}\r\n",
      "2022-09-06 15:55:20,424 (client:259)INFO: {'Role': 'Client #8', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.449393, 'train_total': 777, 'train_imp_ratio': 21.51615, 'train_loss': 349.178202}}\r\n",
      "2022-09-06 15:55:20,527 (client:259)INFO: {'Role': 'Client #12', 'Round': 5, 'Results_raw': {'train_avg_loss': 10.934237, 'train_total': 608, 'train_imp_ratio': -703.204925, 'train_loss': 6648.01619}}\r\n",
      "2022-09-06 15:55:20,563 (client:259)INFO: {'Role': 'Client #2', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.679526, 'train_total': 181, 'train_imp_ratio': -41.16567, 'train_loss': 122.994203}}\r\n",
      "2022-09-06 15:55:46,328 (client:259)INFO: {'Role': 'Client #9', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.053773, 'train_total': 134706, 'train_imp_ratio': 9.164863, 'train_loss': 7243.611868}}\r\n",
      "2022-09-06 15:55:46,803 (client:259)INFO: {'Role': 'Client #11', 'Round': 5, 'Results_raw': {'train_avg_loss': 1.45885, 'train_total': 2268, 'train_imp_ratio': -98.750447, 'train_loss': 3308.672175}}\r\n",
      "2022-09-06 15:56:03,659 (client:259)INFO: {'Role': 'Client #10', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.008629, 'train_total': 109392, 'train_imp_ratio': -21.826263, 'train_loss': 943.938584}}\r\n",
      "2022-09-06 15:56:03,695 (client:259)INFO: {'Role': 'Client #5', 'Round': 5, 'Results_raw': {'train_avg_loss': 0.686829, 'train_total': 188, 'train_imp_ratio': 3.489265, 'train_loss': 129.123894}}\r\n",
      "2022-09-06 15:56:03,702 (server:323)INFO: ----------- Starting a new training round (Round #6) -------------\r\n",
      "2022-09-06 15:56:03,740 (client:259)INFO: {'Role': 'Client #2', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.677592, 'train_total': 181, 'train_imp_ratio': -41.16567, 'train_loss': 122.644159}}\r\n",
      "2022-09-06 15:56:04,208 (client:259)INFO: {'Role': 'Client #3', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.69594, 'train_total': 2219, 'train_imp_ratio': -50.258392, 'train_loss': 1544.290714}}\r\n",
      "2022-09-06 15:56:16,812 (client:259)INFO: {'Role': 'Client #13', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.006119, 'train_total': 70648, 'train_imp_ratio': -39.424888, 'train_loss': 432.320451}}\r\n",
      "2022-09-06 15:56:16,947 (client:259)INFO: {'Role': 'Client #8', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.447918, 'train_total': 777, 'train_imp_ratio': 21.51615, 'train_loss': 348.032411}}\r\n",
      "2022-09-06 15:56:33,769 (client:259)INFO: {'Role': 'Client #10', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.00862, 'train_total': 109392, 'train_imp_ratio': -21.694236, 'train_loss': 942.91549}}\r\n",
      "2022-09-06 15:56:34,239 (client:259)INFO: {'Role': 'Client #7', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.684625, 'train_total': 2228, 'train_imp_ratio': -47.543815, 'train_loss': 1525.34437}}\r\n",
      "2022-09-06 15:57:00,790 (client:259)INFO: {'Role': 'Client #9', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.053636, 'train_total': 134706, 'train_imp_ratio': 9.397761, 'train_loss': 7225.039093}}\r\n",
      "2022-09-06 15:57:01,266 (client:259)INFO: {'Role': 'Client #11', 'Round': 6, 'Results_raw': {'train_avg_loss': 1.422439, 'train_total': 2268, 'train_imp_ratio': -93.789856, 'train_loss': 3226.091461}}\r\n",
      "2022-09-06 15:57:01,303 (client:259)INFO: {'Role': 'Client #5', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.68997, 'train_total': 188, 'train_imp_ratio': -7.23415, 'train_loss': 129.714376}}\r\n",
      "2022-09-06 15:57:01,530 (client:259)INFO: {'Role': 'Client #6', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.676438, 'train_total': 1101, 'train_imp_ratio': -6.9446, 'train_loss': 744.758207}}\r\n",
      "2022-09-06 15:57:01,554 (client:259)INFO: {'Role': 'Client #4', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.670208, 'train_total': 101, 'train_imp_ratio': -96.369179, 'train_loss': 67.690959}}\r\n",
      "2022-09-06 15:57:01,827 (client:259)INFO: {'Role': 'Client #1', 'Round': 6, 'Results_raw': {'train_avg_loss': 0.625773, 'train_total': 1249, 'train_imp_ratio': -35.974946, 'train_loss': 781.590352}}\r\n",
      "2022-09-06 15:57:01,931 (client:259)INFO: {'Role': 'Client #12', 'Round': 6, 'Results_raw': {'train_avg_loss': 10.499172, 'train_total': 608, 'train_imp_ratio': -671.245922, 'train_loss': 6383.496368}}\r\n",
      "2022-09-06 15:57:01,937 (server:323)INFO: ----------- Starting a new training round (Round #7) -------------\r\n",
      "2022-09-06 15:57:02,422 (client:259)INFO: {'Role': 'Client #11', 'Round': 7, 'Results_raw': {'train_avg_loss': 1.422468, 'train_total': 2268, 'train_imp_ratio': -93.79377, 'train_loss': 3226.15647}}\r\n",
      "2022-09-06 15:57:02,877 (client:259)INFO: {'Role': 'Client #3', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.696052, 'train_total': 2219, 'train_imp_ratio': -43.664775, 'train_loss': 1544.539544}}\r\n",
      "2022-09-06 15:57:19,295 (client:259)INFO: {'Role': 'Client #10', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.008608, 'train_total': 109392, 'train_imp_ratio': -21.535755, 'train_loss': 941.687358}}\r\n",
      "2022-09-06 15:57:19,331 (client:259)INFO: {'Role': 'Client #2', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.680605, 'train_total': 181, 'train_imp_ratio': -41.16567, 'train_loss': 123.189455}}\r\n",
      "2022-09-06 15:57:19,592 (client:259)INFO: {'Role': 'Client #1', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.625413, 'train_total': 1249, 'train_imp_ratio': -38.706585, 'train_loss': 781.14032}}\r\n",
      "2022-09-06 15:57:20,042 (client:259)INFO: {'Role': 'Client #7', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.6832, 'train_total': 2228, 'train_imp_ratio': -47.246946, 'train_loss': 1522.17053}}\r\n",
      "2022-09-06 15:57:20,260 (client:259)INFO: {'Role': 'Client #6', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.675689, 'train_total': 1101, 'train_imp_ratio': -6.250155, 'train_loss': 743.933783}}\r\n",
      "2022-09-06 15:57:20,360 (client:259)INFO: {'Role': 'Client #12', 'Round': 7, 'Results_raw': {'train_avg_loss': 10.063821, 'train_total': 608, 'train_imp_ratio': -639.266042, 'train_loss': 6118.803223}}\r\n",
      "2022-09-06 15:57:20,491 (client:259)INFO: {'Role': 'Client #8', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.448662, 'train_total': 777, 'train_imp_ratio': 21.51615, 'train_loss': 348.610138}}\r\n",
      "2022-09-06 15:57:20,514 (client:259)INFO: {'Role': 'Client #4', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.66795, 'train_total': 101, 'train_imp_ratio': -96.369179, 'train_loss': 67.462953}}\r\n",
      "2022-09-06 15:57:32,770 (client:259)INFO: {'Role': 'Client #13', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.005989, 'train_total': 70648, 'train_imp_ratio': -36.457335, 'train_loss': 423.118827}}\r\n",
      "2022-09-06 15:57:57,872 (client:259)INFO: {'Role': 'Client #9', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.05366, 'train_total': 134706, 'train_imp_ratio': 9.357103, 'train_loss': 7228.282679}}\r\n",
      "2022-09-06 15:57:57,908 (client:259)INFO: {'Role': 'Client #5', 'Round': 7, 'Results_raw': {'train_avg_loss': 0.690109, 'train_total': 188, 'train_imp_ratio': -13.936284, 'train_loss': 129.740461}}\r\n",
      "2022-09-06 15:57:57,915 (server:323)INFO: ----------- Starting a new training round (Round #8) -------------\r\n",
      "2022-09-06 15:58:10,158 (client:259)INFO: {'Role': 'Client #13', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.005888, 'train_total': 70648, 'train_imp_ratio': -34.148381, 'train_loss': 415.959318}}\r\n",
      "2022-09-06 15:58:10,616 (client:259)INFO: {'Role': 'Client #7', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.683253, 'train_total': 2228, 'train_imp_ratio': -47.246946, 'train_loss': 1522.286872}}\r\n",
      "2022-09-06 15:58:11,080 (client:259)INFO: {'Role': 'Client #11', 'Round': 8, 'Results_raw': {'train_avg_loss': 1.412159, 'train_total': 2268, 'train_imp_ratio': -92.389314, 'train_loss': 3202.775766}}\r\n",
      "2022-09-06 15:58:36,337 (client:259)INFO: {'Role': 'Client #9', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.05364, 'train_total': 134706, 'train_imp_ratio': 9.390222, 'train_loss': 7225.640963}}\r\n",
      "2022-09-06 15:58:53,240 (client:259)INFO: {'Role': 'Client #10', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.008607, 'train_total': 109392, 'train_imp_ratio': -21.519424, 'train_loss': 941.561415}}\r\n",
      "2022-09-06 15:58:53,379 (client:259)INFO: {'Role': 'Client #8', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.446241, 'train_total': 777, 'train_imp_ratio': 21.51615, 'train_loss': 346.729398}}\r\n",
      "2022-09-06 15:58:53,415 (client:259)INFO: {'Role': 'Client #5', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.687639, 'train_total': 188, 'train_imp_ratio': 8.850973, 'train_loss': 129.276223}}\r\n",
      "2022-09-06 15:58:53,885 (client:259)INFO: {'Role': 'Client #3', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.695356, 'train_total': 2219, 'train_imp_ratio': -47.088384, 'train_loss': 1542.994214}}\r\n",
      "2022-09-06 15:58:53,920 (client:259)INFO: {'Role': 'Client #2', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.679134, 'train_total': 181, 'train_imp_ratio': -41.16567, 'train_loss': 122.923164}}\r\n",
      "2022-09-06 15:58:54,025 (client:259)INFO: {'Role': 'Client #12', 'Round': 8, 'Results_raw': {'train_avg_loss': 9.63764, 'train_total': 608, 'train_imp_ratio': -607.959809, 'train_loss': 5859.685349}}\r\n",
      "2022-09-06 15:58:54,250 (client:259)INFO: {'Role': 'Client #6', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.672484, 'train_total': 1101, 'train_imp_ratio': -2.083482, 'train_loss': 740.40538}}\r\n",
      "2022-09-06 15:58:54,519 (client:259)INFO: {'Role': 'Client #1', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.622217, 'train_total': 1249, 'train_imp_ratio': -36.885492, 'train_loss': 777.149228}}\r\n",
      "2022-09-06 15:58:54,543 (client:259)INFO: {'Role': 'Client #4', 'Round': 8, 'Results_raw': {'train_avg_loss': 0.667214, 'train_total': 101, 'train_imp_ratio': -96.369179, 'train_loss': 67.388659}}\r\n",
      "2022-09-06 15:58:54,550 (server:323)INFO: ----------- Starting a new training round (Round #9) -------------\r\n",
      "2022-09-06 15:59:20,222 (client:259)INFO: {'Role': 'Client #9', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.053667, 'train_total': 134706, 'train_imp_ratio': 9.345014, 'train_loss': 7229.245992}}\r\n",
      "2022-09-06 15:59:20,259 (client:259)INFO: {'Role': 'Client #2', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.680596, 'train_total': 181, 'train_imp_ratio': -41.16567, 'train_loss': 123.187941}}\r\n",
      "2022-09-06 15:59:20,296 (client:259)INFO: {'Role': 'Client #5', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.686246, 'train_total': 188, 'train_imp_ratio': 0.808411, 'train_loss': 129.014255}}\r\n",
      "2022-09-06 15:59:20,789 (client:259)INFO: {'Role': 'Client #11', 'Round': 9, 'Results_raw': {'train_avg_loss': 1.40254, 'train_total': 2268, 'train_imp_ratio': -91.078811, 'train_loss': 3180.959593}}\r\n",
      "2022-09-06 15:59:21,255 (client:259)INFO: {'Role': 'Client #7', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.681481, 'train_total': 2228, 'train_imp_ratio': -47.246946, 'train_loss': 1518.340319}}\r\n",
      "2022-09-06 15:59:21,279 (client:259)INFO: {'Role': 'Client #4', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.666843, 'train_total': 101, 'train_imp_ratio': -96.369179, 'train_loss': 67.351186}}\r\n",
      "2022-09-06 15:59:21,385 (client:259)INFO: {'Role': 'Client #12', 'Round': 9, 'Results_raw': {'train_avg_loss': 9.259982, 'train_total': 608, 'train_imp_ratio': -580.217825, 'train_loss': 5630.069336}}\r\n",
      "2022-09-06 15:59:21,860 (client:259)INFO: {'Role': 'Client #3', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.693932, 'train_total': 2219, 'train_imp_ratio': -41.76277, 'train_loss': 1539.835388}}\r\n",
      "2022-09-06 15:59:34,306 (client:259)INFO: {'Role': 'Client #13', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.005813, 'train_total': 70648, 'train_imp_ratio': -32.448075, 'train_loss': 410.687081}}\r\n",
      "2022-09-06 15:59:51,086 (client:259)INFO: {'Role': 'Client #10', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.008602, 'train_total': 109392, 'train_imp_ratio': -21.445384, 'train_loss': 940.987426}}\r\n",
      "2022-09-06 15:59:51,312 (client:259)INFO: {'Role': 'Client #6', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.671609, 'train_total': 1101, 'train_imp_ratio': -3.12515, 'train_loss': 739.441862}}\r\n",
      "2022-09-06 15:59:51,448 (client:259)INFO: {'Role': 'Client #8', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.446934, 'train_total': 777, 'train_imp_ratio': 21.51615, 'train_loss': 347.267962}}\r\n",
      "2022-09-06 15:59:51,719 (client:259)INFO: {'Role': 'Client #1', 'Round': 9, 'Results_raw': {'train_avg_loss': 0.618726, 'train_total': 1249, 'train_imp_ratio': -42.045256, 'train_loss': 772.788947}}\r\n",
      "2022-09-06 15:59:51,726 (server:334)INFO: Server #0: Training is finished! Starting evaluation.\r\n",
      "2022-09-06 16:00:13,922 (server:489)INFO: {'Role': 'Server #', 'Round': 10, 'Results_avg': {'test_avg_loss': 1.163724, 'test_total': 8350.846154, 'test_imp_ratio': -1062.021539, 'test_loss': 8163.426832, 'val_avg_loss': 1.22281, 'val_total': 8350.461538, 'val_imp_ratio': -159.374074, 'val_loss': 833.02988}}\r\n",
      "2022-09-06 16:00:13,922 (server:388)INFO: Server #0: Final evaluation is finished! Starting merging results.\r\n",
      "2022-09-06 16:00:13,922 (server:418)INFO: {'Role': 'Server #', 'Round': 'Final', 'Results_raw': {'client_best_individual': {}, 'client_summarized_avg': {}}}\r\n",
      "2022-09-06 16:00:13,922 (server:439)INFO: {'Role': 'Client #1', 'Round': 10, 'Results_raw': {'test_avg_loss': 0.897458, 'test_total': 417, 'test_imp_ratio': -279.090864, 'test_loss': 374.239941, 'val_avg_loss': 0.751108, 'val_total': 416, 'val_imp_ratio': -131.464133, 'val_loss': 312.460745}}\r\n",
      "2022-09-06 16:00:13,923 (server:439)INFO: {'Role': 'Client #2', 'Round': 10, 'Results_raw': {'test_avg_loss': 0.579195, 'test_total': 61, 'test_imp_ratio': 100.0, 'test_loss': 35.330898, 'val_avg_loss': 0.680191, 'val_total': 60, 'val_imp_ratio': -43.868166, 'val_loss': 40.811476}}\r\n",
      "2022-09-06 16:00:13,923 (server:439)INFO: {'Role': 'Client #3', 'Round': 10, 'Results_raw': {'test_avg_loss': 0.655669, 'test_total': 740, 'test_imp_ratio': 100.0, 'test_loss': 485.194695, 'val_avg_loss': 0.690249, 'val_total': 740, 'val_imp_ratio': -23.574633, 'val_loss': 510.784334}}\r\n",
      "2022-09-06 16:00:13,923 (server:439)INFO: {'Role': 'Client #4', 'Round': 10, 'Results_raw': {'test_avg_loss': 0.856257, 'test_total': 34, 'test_imp_ratio': -466.665344, 'test_loss': 29.11275, 'val_avg_loss': 0.648201, 'val_total': 34, 'val_imp_ratio': -83.332906, 'val_loss': 22.038817}}\r\n",
      "2022-09-06 16:00:13,923 (server:439)INFO: {'Role': 'Client #5', 'Round': 10, 'Results_raw': {'test_avg_loss': 0.689172, 'test_total': 63, 'test_imp_ratio': 47.999948, 'test_loss': 43.417839, 'val_avg_loss': 0.692289, 'val_total': 63, 'val_imp_ratio': -16.000116, 'val_loss': 43.614234}}\r\n",
      "2022-09-06 16:00:13,923 (server:439)INFO: {'Role': 'Client #6', 'Round': 10, 'Results_raw': {'test_avg_loss': 0.700973, 'test_total': 367, 'test_imp_ratio': -146.87536, 'test_loss': 257.257049, 'val_avg_loss': 0.685994, 'val_total': 367, 'val_imp_ratio': -31.250191, 'val_loss': 251.759814}}\r\n",
      "2022-09-06 16:00:13,924 (server:439)INFO: {'Role': 'Client #7', 'Round': 10, 'Results_raw': {'test_avg_loss': 0.622654, 'test_total': 743, 'test_imp_ratio': 100.0, 'test_loss': 462.632187, 'val_avg_loss': 0.689622, 'val_total': 743, 'val_imp_ratio': -51.780289, 'val_loss': 512.38945}}\r\n",
      "2022-09-06 16:00:13,924 (server:439)INFO: {'Role': 'Client #8', 'Round': 10, 'Results_raw': {'test_avg_loss': 2.061352, 'test_total': 260, 'test_imp_ratio': -372.728304, 'test_loss': 535.951649, 'val_avg_loss': 0.396561, 'val_total': 259, 'val_imp_ratio': 37.943003, 'val_loss': 102.709333}}\r\n",
      "2022-09-06 16:00:13,924 (server:439)INFO: {'Role': 'Client #9', 'Round': 10, 'Results_raw': {'test_avg_loss': 1.949834, 'test_total': 44902, 'test_imp_ratio': -3193.693528, 'test_loss': 87551.432259, 'val_avg_loss': 0.100442, 'val_total': 44902, 'val_imp_ratio': -69.667739, 'val_loss': 4510.029088}}\r\n",
      "2022-09-06 16:00:13,924 (server:439)INFO: {'Role': 'Client #10', 'Round': 10, 'Results_raw': {'test_avg_loss': 0.138781, 'test_total': 36465, 'test_imp_ratio': -1859.34912, 'test_loss': 5060.638654, 'val_avg_loss': 0.017899, 'val_total': 36464, 'val_imp_ratio': -152.698412, 'val_loss': 652.655581}}\r\n",
      "2022-09-06 16:00:13,924 (server:439)INFO: {'Role': 'Client #11', 'Round': 10, 'Results_raw': {'test_avg_loss': 4.429338, 'test_total': 756, 'test_imp_ratio': -503.442997, 'test_loss': 3348.57962, 'val_avg_loss': 1.370054, 'val_total': 756, 'val_imp_ratio': -86.653046, 'val_loss': 1035.76077}}\r\n",
      "2022-09-06 16:00:13,925 (server:439)INFO: {'Role': 'Client #12', 'Round': 10, 'Results_raw': {'test_avg_loss': 1.221072, 'test_total': 203, 'test_imp_ratio': 10.302769, 'test_loss': 247.877547, 'val_avg_loss': 9.132278, 'val_total': 203, 'val_imp_ratio': -570.836996, 'val_loss': 1853.852477}}\r\n",
      "2022-09-06 16:00:13,925 (server:439)INFO: {'Role': 'Client #13', 'Round': 10, 'Results_raw': {'test_avg_loss': 0.326662, 'test_total': 23550, 'test_imp_ratio': -7342.737201, 'test_loss': 7692.883722, 'val_avg_loss': 0.041638, 'val_total': 23549, 'val_imp_ratio': -848.679338, 'val_loss': 980.522322}}\r\n",
      "2022-09-06 16:00:13,925 (monitor:121)INFO: In worker #0, the system-related metrics are: {'id': 0, 'fl_end_time_minutes': 10.474232, 'total_model_size': 0, 'total_flops': 0, 'total_upload_bytes': 2919488, 'total_download_bytes': 1250800, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:13,926 (client:440)INFO: ================= client 1 received finish message =================\r\n",
      "2022-09-06 16:00:13,979 (client:453)INFO: Client #1 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846/prediction.csv\r\n",
      "2022-09-06 16:00:13,980 (monitor:121)INFO: In worker #1, the system-related metrics are: {'id': 1, 'fl_end_time_minutes': 10.474862, 'total_model_size': 304514, 'total_flops': 0, 'total_upload_bytes': 96296, 'total_download_bytes': 224576, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:13,980 (client:440)INFO: ================= client 2 received finish message =================\r\n",
      "2022-09-06 16:00:13,991 (client:453)INFO: Client #2 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846/prediction.csv\r\n",
      "2022-09-06 16:00:13,991 (monitor:121)INFO: In worker #2, the system-related metrics are: {'id': 2, 'fl_end_time_minutes': 10.474785, 'total_model_size': 278786, 'total_flops': 0, 'total_upload_bytes': 96296, 'total_download_bytes': 224576, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:13,991 (client:440)INFO: ================= client 3 received finish message =================\r\n",
      "2022-09-06 16:00:14,079 (client:453)INFO: Client #3 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846/prediction.csv\r\n",
      "2022-09-06 16:00:14,079 (monitor:121)INFO: In worker #3, the system-related metrics are: {'id': 3, 'fl_end_time_minutes': 10.475961, 'total_model_size': 497474, 'total_flops': 0, 'total_upload_bytes': 96296, 'total_download_bytes': 224576, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:14,079 (client:440)INFO: ================= client 4 received finish message =================\r\n",
      "2022-09-06 16:00:14,088 (client:453)INFO: Client #4 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846/prediction.csv\r\n",
      "2022-09-06 16:00:14,088 (monitor:121)INFO: In worker #4, the system-related metrics are: {'id': 4, 'fl_end_time_minutes': 10.475871, 'total_model_size': 111554, 'total_flops': 0, 'total_upload_bytes': 96264, 'total_download_bytes': 224576, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:14,088 (client:440)INFO: ================= client 5 received finish message =================\r\n",
      "2022-09-06 16:00:14,099 (client:453)INFO: Client #5 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846/prediction.csv\r\n",
      "2022-09-06 16:00:14,099 (monitor:121)INFO: In worker #5, the system-related metrics are: {'id': 5, 'fl_end_time_minutes': 10.475793, 'total_model_size': 253058, 'total_flops': 0, 'total_upload_bytes': 96264, 'total_download_bytes': 224576, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:14,099 (client:440)INFO: ================= client 6 received finish message =================\r\n",
      "2022-09-06 16:00:14,146 (client:453)INFO: Client #6 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846/prediction.csv\r\n",
      "2022-09-06 16:00:14,146 (monitor:121)INFO: In worker #6, the system-related metrics are: {'id': 6, 'fl_end_time_minutes': 10.476311, 'total_model_size': 304514, 'total_flops': 0, 'total_upload_bytes': 96296, 'total_download_bytes': 224576, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:14,146 (client:440)INFO: ================= client 7 received finish message =================\r\n",
      "2022-09-06 16:00:14,235 (client:453)INFO: Client #7 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846/prediction.csv\r\n",
      "2022-09-06 16:00:14,235 (monitor:121)INFO: In worker #7, the system-related metrics are: {'id': 7, 'fl_end_time_minutes': 10.477507, 'total_model_size': 510338, 'total_flops': 0, 'total_upload_bytes': 96296, 'total_download_bytes': 224576, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:14,235 (client:440)INFO: ================= client 8 received finish message =================\r\n",
      "2022-09-06 16:00:14,267 (client:453)INFO: Client #8 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846/prediction.csv\r\n",
      "2022-09-06 16:00:14,267 (monitor:121)INFO: In worker #8, the system-related metrics are: {'id': 8, 'fl_end_time_minutes': 10.477773, 'total_model_size': 265922, 'total_flops': 0, 'total_upload_bytes': 96296, 'total_download_bytes': 224576, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:14,268 (client:440)INFO: ================= client 9 received finish message =================\r\n",
      "2022-09-06 16:00:19,071 (client:453)INFO: Client #9 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846/prediction.csv\r\n",
      "2022-09-06 16:00:19,071 (monitor:121)INFO: In worker #9, the system-related metrics are: {'id': 9, 'fl_end_time_minutes': 10.557488, 'total_model_size': 381633, 'total_flops': 0, 'total_upload_bytes': 96328, 'total_download_bytes': 224576, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:19,072 (client:440)INFO: ================= client 10 received finish message =================\r\n",
      "2022-09-06 16:00:22,716 (client:453)INFO: Client #10 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846/prediction.csv\r\n",
      "2022-09-06 16:00:22,716 (monitor:121)INFO: In worker #10, the system-related metrics are: {'id': 10, 'fl_end_time_minutes': 10.617959, 'total_model_size': 99210, 'total_flops': 0, 'total_upload_bytes': 96328, 'total_download_bytes': 224576, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:22,716 (client:440)INFO: ================= client 11 received finish message =================\r\n",
      "2022-09-06 16:00:22,810 (client:453)INFO: Client #11 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846/prediction.csv\r\n",
      "2022-09-06 16:00:22,810 (monitor:121)INFO: In worker #11, the system-related metrics are: {'id': 11, 'fl_end_time_minutes': 10.619239, 'total_model_size': 304449, 'total_flops': 0, 'total_upload_bytes': 96328, 'total_download_bytes': 224576, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:22,810 (client:440)INFO: ================= client 12 received finish message =================\r\n",
      "2022-09-06 16:00:22,836 (client:453)INFO: Client #12 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846/prediction.csv\r\n",
      "2022-09-06 16:00:22,837 (monitor:121)INFO: In worker #12, the system-related metrics are: {'id': 12, 'fl_end_time_minutes': 10.619422, 'total_model_size': 304449, 'total_flops': 0, 'total_upload_bytes': 96296, 'total_download_bytes': 224576, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:22,837 (client:440)INFO: ================= client 13 received finish message =================\r\n",
      "2022-09-06 16:00:25,375 (client:453)INFO: Client #13 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220906154846/prediction.csv\r\n",
      "2022-09-06 16:00:25,375 (monitor:121)INFO: In worker #13, the system-related metrics are: {'id': 13, 'fl_end_time_minutes': 10.661459, 'total_model_size': 163660, 'total_flops': 0, 'total_upload_bytes': 96328, 'total_download_bytes': 224576, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-06 16:00:25,375 (monitor:278)INFO: We will compress the file eval_results.raw into a .gz file, and delete the old one\r\n",
      "2022-09-06 16:00:25,377 (monitor:195)INFO: After merging the system metrics from all works, we got avg: defaultdict(None, {'id': 'sys_avg', 'sys_avg/fl_end_time_minutes': 10.525619, 'sys_avg/total_model_size': '263.64K', 'sys_avg/total_flops': '0.0', 'sys_avg/total_upload_bytes': '290.97K', 'sys_avg/total_download_bytes': '290.9K', 'sys_avg/global_convergence_round': 0.0, 'sys_avg/local_convergence_round': 0.0, 'sys_avg/global_convergence_time_minutes': 0.0, 'sys_avg/local_convergence_time_minutes': 0.0})\r\n",
      "2022-09-06 16:00:25,377 (monitor:198)INFO: After merging the system metrics from all works, we got std: defaultdict(None, {'id': 'sys_std', 'sys_std/fl_end_time_minutes': 0.0696, 'sys_std/total_model_size': '134.51K', 'sys_std/total_flops': '0.0', 'sys_std/total_upload_bytes': '710.04K', 'sys_std/total_download_bytes': '258.1K', 'sys_std/global_convergence_round': 0.0, 'sys_std/local_convergence_round': 0.0, 'sys_std/global_convergence_time_minutes': 0.0, 'sys_std/local_convergence_time_minutes': 0.0})\r\n"
     ]
    }
   ],
   "source": [
    "!python federatedscope/main.py --cfg federatedscope/gfl/baseline/fedavg_gin_minibatch_on_cikmcup.yaml --client_cfg federatedscope/gfl/baseline/fedavg_gin_minibatch_on_cikmcup_per_client.yaml federate.total_round_num 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}