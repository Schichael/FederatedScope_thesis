{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[43, 22], edge_index=[2, 98], edge_attr=[98, 8], y=[1, 1], data_index=0)\n",
      "1249\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# The train split of client 1\n",
    "train_data_client1 = torch.load('./data/CIKM22Competition/1/train.pt')\n",
    "# Check the first sample\n",
    "print(train_data_client1[0])\n",
    "# Check the label of the first sample\n",
    "print(len(train_data_client1))\n",
    "# Check the index of the first sample as ${sample_id}\n",
    "print(train_data_client1[0].data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "ys = [train_data_client1[i].y for i in range(len(train_data_client1)-1)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[485]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ys)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.3886]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ys) / len(ys)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.6114]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- sum(ys) / len(ys)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1: 1249\n",
    "2: 181\n",
    "3: 2219\n",
    "4: 101\n",
    "5: 188\n",
    "6: 1101\n",
    "7: 2228\n",
    "8: 777\n",
    "9: 134706\n",
    "10: 109392\n",
    "11: 2268\n",
    "12: 608\n",
    "13: 70648"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1: 0\n",
    "2: 0\n",
    "3: 0\n",
    "4:1\n",
    "5:0\n",
    "6:1\n",
    "7:0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = [1249, 181, 2219, 101, 188, 1101, 2228, 777, 134706, 109392, 2268, 608, 70648]\n",
    "a/np.array(sum(a))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-13 12:39:32,796 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \r\n",
      "2022-09-13 12:39:32,796 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \r\n",
      "2022-09-13 12:39:32,797 (utils:129)INFO: the current machine is at 127.0.1.1\r\n",
      "2022-09-13 12:39:32,797 (utils:131)INFO: the current dir is /home/michael/Master thesis/Code/FederatedScope_thesis\r\n",
      "2022-09-13 12:39:32,797 (utils:132)INFO: the output dir is exp/local_gin_on_cikmcup_lr0.1_lstep21_/sub_exp_20220913123932\r\n",
      "2022-09-13 12:39:32,888 (cikm_cup:57)INFO: Loading CIKMCUP data from /home/michael/Master thesis/Code/FederatedScope_thesis/data/CIKM22Competition.\r\n",
      "2022-09-13 12:39:32,889 (cfg_fl_setting:104)WARNING: In local/global training mode, the sampling related configs are in-valid, we will use all clients. \r\n",
      "2022-09-13 12:39:32,889 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #1.\r\n",
      "2022-09-13 12:39:33,122 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #2.\r\n",
      "2022-09-13 12:39:33,139 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #3.\r\n",
      "2022-09-13 12:39:33,436 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #4.\r\n",
      "2022-09-13 12:39:33,445 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #5.\r\n",
      "2022-09-13 12:39:33,462 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #6.\r\n",
      "2022-09-13 12:39:33,595 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #7.\r\n",
      "2022-09-13 12:39:33,943 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #8.\r\n",
      "2022-09-13 12:39:34,041 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #9.\r\n",
      "2022-09-13 12:39:55,363 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #10.\r\n",
      "2022-09-13 12:40:14,291 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #11.\r\n",
      "2022-09-13 12:40:14,591 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #12.\r\n",
      "2022-09-13 12:40:14,656 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #13.\r\n"
     ]
    }
   ],
   "source": [
    "!python federatedscope/main.py --cfg federatedscope/gfl/baseline/isolated_gin_minibatch_on_cikmcup.yaml --client_cfg federatedscope/gfl/baseline/isolated_gin_minibatch_on_cikmcup_per_client.yaml federate.total_round_num 3\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del train_data_client1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-09-13 12:40:30,761 (utils:129)INFO: the current machine is at 127.0.1.1\r\n",
      "2022-09-13 12:40:30,761 (utils:131)INFO: the current dir is /home/michael/Master thesis/Code/FederatedScope_thesis\r\n",
      "2022-09-13 12:40:30,761 (utils:132)INFO: the output dir is exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "2022-09-13 12:40:30,810 (cikm_cup:57)INFO: Loading CIKMCUP data from /home/michael/Master thesis/Code/FederatedScope_thesis/data/CIKM22Competition.\r\n",
      "2022-09-13 12:40:30,810 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #1.\r\n",
      "2022-09-13 12:40:30,998 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #2.\r\n",
      "2022-09-13 12:40:31,012 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #3.\r\n",
      "2022-09-13 12:40:31,255 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #4.\r\n",
      "2022-09-13 12:40:31,262 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #5.\r\n",
      "2022-09-13 12:40:31,277 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #6.\r\n",
      "2022-09-13 12:40:31,383 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #7.\r\n",
      "2022-09-13 12:40:31,630 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #8.\r\n",
      "2022-09-13 12:40:31,705 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #9.\r\n",
      "2022-09-13 12:40:51,579 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #10.\r\n",
      "2022-09-13 12:41:10,268 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #11.\r\n",
      "2022-09-13 12:41:10,467 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #12.\r\n",
      "2022-09-13 12:41:10,515 (cikm_cup:67)INFO: Loading CIKMCUP data for Client #13.\r\n",
      "2022-09-13 12:41:23,836 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: MSELoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.0\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 1\r\n",
      "  task: graph\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:23,872 (fed_runner:249)INFO: Server #0 has been set up ... \r\n",
      "2022-09-13 12:41:23,881 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.263789\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['acc', 'imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:23,887 (fed_runner:302)INFO: Client 1 has been set up ... \r\n",
      "2022-09-13 12:41:23,897 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.289617\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['acc', 'imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.01\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:23,903 (fed_runner:302)INFO: Client 2 has been set up ... \r\n",
      "2022-09-13 12:41:23,912 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.355404\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['acc', 'imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.001\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:23,920 (fed_runner:302)INFO: Client 3 has been set up ... \r\n",
      "2022-09-13 12:41:23,929 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.176471\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['acc', 'imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.01\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:23,934 (fed_runner:302)INFO: Client 4 has been set up ... \r\n",
      "2022-09-13 12:41:23,943 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.396825\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['acc', 'imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.0001\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:23,948 (fed_runner:302)INFO: Client 5 has been set up ... \r\n",
      "2022-09-13 12:41:23,958 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.26158\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['acc', 'imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.0005\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:23,964 (fed_runner:302)INFO: Client 6 has been set up ... \r\n",
      "2022-09-13 12:41:23,973 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.302378\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['acc', 'imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.01\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:23,982 (fed_runner:302)INFO: Client 7 has been set up ... \r\n",
      "2022-09-13 12:41:23,991 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: CrossEntropyLoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.211538\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 2\r\n",
      "  task: graphClassification\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.05\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:23,997 (fed_runner:302)INFO: Client 8 has been set up ... \r\n",
      "2022-09-13 12:41:24,007 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: MSELoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.059199\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 1\r\n",
      "  task: graphRegression\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:24,017 (fed_runner:302)INFO: Client 9 has been set up ... \r\n",
      "2022-09-13 12:41:24,027 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: MSELoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.007083\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 10\r\n",
      "  task: graphRegression\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.05\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:24,033 (fed_runner:302)INFO: Client 10 has been set up ... \r\n",
      "2022-09-13 12:41:24,043 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: MSELoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.734011\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 1\r\n",
      "  task: graphRegression\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.05\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:24,049 (fed_runner:302)INFO: Client 11 has been set up ... \r\n",
      "2022-09-13 12:41:24,059 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: MSELoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 1.361326\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 1\r\n",
      "  task: graphRegression\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.01\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:24,065 (fed_runner:302)INFO: Client 12 has been set up ... \r\n",
      "2022-09-13 12:41:24,075 (config:261)INFO: the used configs are: \r\n",
      "asyn:\r\n",
      "  min_received_num: 13\r\n",
      "  min_received_rate: -1.0\r\n",
      "  timeout: 0\r\n",
      "  use: True\r\n",
      "attack:\r\n",
      "  alpha_TV: 0.001\r\n",
      "  alpha_prop_loss: 0\r\n",
      "  attack_method: \r\n",
      "  attacker_id: -1\r\n",
      "  classifier_PIA: randomforest\r\n",
      "  info_diff_type: l2\r\n",
      "  inject_round: 0\r\n",
      "  max_ite: 400\r\n",
      "  reconstruct_lr: 0.01\r\n",
      "  reconstruct_optim: Adam\r\n",
      "  target_label_ind: -1\r\n",
      "backend: torch\r\n",
      "cfg_file: \r\n",
      "criterion:\r\n",
      "  type: MSELoss\r\n",
      "data:\r\n",
      "  args: []\r\n",
      "  batch_size: 32\r\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\r\n",
      "  consistent_label_distribution: False\r\n",
      "  drop_last: False\r\n",
      "  graphsaint:\r\n",
      "    num_steps: 30\r\n",
      "    walk_length: 2\r\n",
      "  loader: \r\n",
      "  num_workers: 0\r\n",
      "  pre_transform: []\r\n",
      "  quadratic:\r\n",
      "    dim: 1\r\n",
      "    max_curv: 12.5\r\n",
      "    min_curv: 0.02\r\n",
      "  root: data/\r\n",
      "  server_holds_all: False\r\n",
      "  shuffle: True\r\n",
      "  sizes: [10, 5]\r\n",
      "  splits: [0.8, 0.1, 0.1]\r\n",
      "  splitter: \r\n",
      "  splitter_args: []\r\n",
      "  subsample: 1.0\r\n",
      "  target_transform: []\r\n",
      "  transform: []\r\n",
      "  type: cikmcup\r\n",
      "device: 0\r\n",
      "distribute:\r\n",
      "  use: False\r\n",
      "early_stop:\r\n",
      "  delta: 0.0\r\n",
      "  improve_indicator_mode: mean\r\n",
      "  patience: 20\r\n",
      "  the_smaller_the_better: False\r\n",
      "eval:\r\n",
      "  base: 0.004389\r\n",
      "  best_res_update_round_wise_key: val_imp_ratio\r\n",
      "  count_flops: False\r\n",
      "  freq: 1\r\n",
      "  metrics: ['imp_ratio']\r\n",
      "  monitoring: []\r\n",
      "  report: ['avg']\r\n",
      "  save_data: False\r\n",
      "  split: ['test', 'val']\r\n",
      "expname: FedAvg_gin_on_cikmcup_lr0.1_lstep1_\r\n",
      "expname_tag: \r\n",
      "federate:\r\n",
      "  client_num: 13\r\n",
      "  data_weighted_aggr: False\r\n",
      "  ignore_weight: False\r\n",
      "  join_in_info: []\r\n",
      "  make_global_eval: False\r\n",
      "  method: FedAvg\r\n",
      "  mode: standalone\r\n",
      "  online_aggr: False\r\n",
      "  restore_from: \r\n",
      "  sample_client_num: 13\r\n",
      "  sample_client_rate: -1.0\r\n",
      "  sampler: uniform\r\n",
      "  save_to: \r\n",
      "  share_local_model: False\r\n",
      "  total_round_num: 3\r\n",
      "  unseen_clients_rate: 0.0\r\n",
      "  use_diff: False\r\n",
      "  use_ss: False\r\n",
      "fedopt:\r\n",
      "  use: False\r\n",
      "fedprox:\r\n",
      "  use: False\r\n",
      "fedsageplus:\r\n",
      "  a: 1.0\r\n",
      "  b: 1.0\r\n",
      "  c: 1.0\r\n",
      "  fedgen_epoch: 200\r\n",
      "  gen_hidden: 128\r\n",
      "  hide_portion: 0.5\r\n",
      "  loc_epoch: 1\r\n",
      "  num_pred: 5\r\n",
      "finetune:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  before_eval: False\r\n",
      "  freeze_param: \r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.1\r\n",
      "    type: SGD\r\n",
      "flitplus:\r\n",
      "  factor_ema: 0.8\r\n",
      "  lambdavat: 0.5\r\n",
      "  tmpFed: 0.5\r\n",
      "  weightReg: 1.0\r\n",
      "gcflplus:\r\n",
      "  EPS_1: 0.05\r\n",
      "  EPS_2: 0.1\r\n",
      "  seq_length: 5\r\n",
      "  standardize: False\r\n",
      "grad:\r\n",
      "  grad_clip: 0.5\r\n",
      "hpo:\r\n",
      "  fedex:\r\n",
      "    cutoff: 0.0\r\n",
      "    diff: False\r\n",
      "    eta0: -1.0\r\n",
      "    flatten_ss: True\r\n",
      "    gamma: 0.0\r\n",
      "    num_arms: 16\r\n",
      "    sched: auto\r\n",
      "    ss: \r\n",
      "    use: False\r\n",
      "  init_cand_num: 16\r\n",
      "  larger_better: False\r\n",
      "  log_scale: False\r\n",
      "  metric: client_summarized_weighted_avg.val_loss\r\n",
      "  num_workers: 0\r\n",
      "  pbt:\r\n",
      "    max_stage: 5\r\n",
      "    perf_threshold: 0.1\r\n",
      "  plot_interval: 1\r\n",
      "  scheduler: rs\r\n",
      "  sha:\r\n",
      "    budgets: []\r\n",
      "    elim_rate: 3\r\n",
      "    elim_round_num: 3\r\n",
      "  ss: \r\n",
      "  table:\r\n",
      "    eps: 0.1\r\n",
      "    idx: 0\r\n",
      "    num: 27\r\n",
      "    ss: \r\n",
      "  working_folder: hpo\r\n",
      "model:\r\n",
      "  dropout: 0.0\r\n",
      "  embed_size: 8\r\n",
      "  graph_pooling: mean\r\n",
      "  hidden: 64\r\n",
      "  in_channels: 0\r\n",
      "  layer: 2\r\n",
      "  model_num_per_trainer: 1\r\n",
      "  num_item: 0\r\n",
      "  num_user: 0\r\n",
      "  out_channels: 12\r\n",
      "  task: graphRegression\r\n",
      "  type: gin\r\n",
      "  use_bias: True\r\n",
      "nbafl:\r\n",
      "  use: False\r\n",
      "outdir: exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030\r\n",
      "personalization:\r\n",
      "  K: 5\r\n",
      "  beta: 1.0\r\n",
      "  local_param: ['encoder_atom', 'encoder', 'clf']\r\n",
      "  local_update_steps: 1\r\n",
      "  lr: 0.1\r\n",
      "  regular_weight: 0.1\r\n",
      "  share_non_trainable_para: False\r\n",
      "print_decimal_digits: 6\r\n",
      "regularizer:\r\n",
      "  mu: 0.0\r\n",
      "  type: \r\n",
      "seed: 0\r\n",
      "sgdmf:\r\n",
      "  use: False\r\n",
      "train:\r\n",
      "  batch_or_epoch: epoch\r\n",
      "  local_update_steps: 1\r\n",
      "  optimizer:\r\n",
      "    lr: 0.05\r\n",
      "    type: SGD\r\n",
      "    weight_decay: 0.0005\r\n",
      "trainer:\r\n",
      "  type: graphminibatch_trainer\r\n",
      "use_gpu: False\r\n",
      "verbose: 1\r\n",
      "vertical:\r\n",
      "  use: False\r\n",
      "wandb:\r\n",
      "  use: False\r\n",
      "2022-09-13 12:41:24,082 (fed_runner:302)INFO: Client 13 has been set up ... \r\n",
      "2022-09-13 12:41:24,082 (trainer:330)INFO: Model meta-info: <class 'federatedscope.gfl.model.graph_level.GNN_Net_Graph'>.\r\n",
      "2022-09-13 12:41:24,083 (trainer:338)INFO: Num of original para names: 58.\r\n",
      "2022-09-13 12:41:24,083 (trainer:339)INFO: Num of original trainable para names: 44.\r\n",
      "2022-09-13 12:41:24,083 (trainer:341)INFO: Num of preserved para names in local update: 32. \r\n",
      "Preserved para names in local update: {'linear.0.bias', 'gnn.convs.1.nn.norms.1.running_mean', 'gnn.convs.0.nn.norms.1.running_mean', 'linear.0.weight', 'gnn.convs.0.nn.linears.1.weight', 'gnn.convs.0.eps', 'gnn.convs.0.nn.norms.0.running_var', 'gnn.convs.1.nn.norms.1.bias', 'gnn.convs.0.nn.linears.0.weight', 'gnn.convs.0.nn.norms.0.running_mean', 'gnn.convs.0.nn.norms.0.bias', 'gnn.convs.0.nn.norms.0.num_batches_tracked', 'gnn.convs.1.nn.linears.0.weight', 'gnn.convs.1.nn.linears.1.weight', 'gnn.convs.1.eps', 'gnn.convs.0.nn.norms.1.running_var', 'gnn.convs.0.nn.linears.0.bias', 'gnn.convs.1.nn.linears.0.bias', 'gnn.convs.1.nn.norms.0.running_var', 'gnn.convs.1.nn.norms.1.weight', 'gnn.convs.1.nn.norms.0.num_batches_tracked', 'gnn.convs.1.nn.norms.0.weight', 'gnn.convs.0.nn.linears.1.bias', 'gnn.convs.0.nn.norms.1.bias', 'gnn.convs.1.nn.norms.0.bias', 'gnn.convs.1.nn.norms.0.running_mean', 'gnn.convs.0.nn.norms.0.weight', 'gnn.convs.0.nn.norms.1.weight', 'gnn.convs.1.nn.linears.1.bias', 'gnn.convs.1.nn.norms.1.num_batches_tracked', 'gnn.convs.0.nn.norms.1.num_batches_tracked', 'gnn.convs.1.nn.norms.1.running_var'}.\r\n",
      "2022-09-13 12:41:24,083 (trainer:345)INFO: Num of filtered para names in local update: 26. \r\n",
      "Filtered para names in local update: {'clf.weight', 'encoder_atom.atom_embedding_list.17.weight', 'clf.bias', 'encoder_atom.atom_embedding_list.4.weight', 'encoder_atom.atom_embedding_list.2.weight', 'encoder_atom.atom_embedding_list.18.weight', 'encoder_atom.atom_embedding_list.6.weight', 'encoder_atom.atom_embedding_list.0.weight', 'encoder_atom.atom_embedding_list.9.weight', 'encoder_atom.atom_embedding_list.15.weight', 'encoder_atom.atom_embedding_list.11.weight', 'encoder_atom.atom_embedding_list.1.weight', 'encoder_atom.atom_embedding_list.20.weight', 'encoder_atom.atom_embedding_list.19.weight', 'encoder_atom.atom_embedding_list.21.weight', 'encoder_atom.atom_embedding_list.16.weight', 'encoder_atom.atom_embedding_list.10.weight', 'encoder_atom.atom_embedding_list.12.weight', 'encoder.bias', 'encoder_atom.atom_embedding_list.8.weight', 'encoder_atom.atom_embedding_list.13.weight', 'encoder_atom.atom_embedding_list.14.weight', 'encoder_atom.atom_embedding_list.5.weight', 'encoder_atom.atom_embedding_list.7.weight', 'encoder.weight', 'encoder_atom.atom_embedding_list.3.weight'}.\r\n",
      "2022-09-13 12:41:24,083 (trainer:350)INFO: After register default hooks,\r\n",
      "\tthe hooks_in_train is:\r\n",
      "\t{\r\n",
      "\t  \"on_fit_start\": [\r\n",
      "\t    \"_hook_on_fit_start_init\",\r\n",
      "\t    \"_hook_on_fit_start_calculate_model_size\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_epoch_start\": [\r\n",
      "\t    \"_hook_on_epoch_start\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_start\": [\r\n",
      "\t    \"_hook_on_batch_start_init\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_forward\": [\r\n",
      "\t    \"_hook_on_batch_forward\",\r\n",
      "\t    \"_hook_on_batch_forward_regularizer\",\r\n",
      "\t    \"_hook_on_batch_forward_flop_count\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_backward\": [\r\n",
      "\t    \"_hook_on_batch_backward\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_end\": [\r\n",
      "\t    \"_hook_on_batch_end\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_fit_end\": [\r\n",
      "\t    \"_hook_on_fit_end\"\r\n",
      "\t  ]\r\n",
      "\t};\r\n",
      "\tthe hooks_in_eval is:\r\n",
      "            t{\r\n",
      "\t  \"on_fit_start\": [\r\n",
      "\t    \"_hook_on_fit_start_init\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_epoch_start\": [\r\n",
      "\t    \"_hook_on_epoch_start\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_start\": [\r\n",
      "\t    \"_hook_on_batch_start_init\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_forward\": [\r\n",
      "\t    \"_hook_on_batch_forward\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_batch_end\": [\r\n",
      "\t    \"_hook_on_batch_end\"\r\n",
      "\t  ],\r\n",
      "\t  \"on_fit_end\": [\r\n",
      "\t    \"_hook_on_fit_end\"\r\n",
      "\t  ]\r\n",
      "\t}\r\n",
      "2022-09-13 12:41:24,086 (server:637)INFO: ----------- Starting training (Round #0) -------------\r\n",
      "before train name: encoder_atom.atom_embedding_list.34.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0550, -0.0620,  0.0381,  ...,  0.0264, -0.0695, -0.1250],\r\n",
      "        [-0.0690,  0.1212, -0.0542,  ...,  0.0780,  0.1470,  0.0069],\r\n",
      "        [ 0.1111, -0.0047,  0.0179,  ...,  0.0364, -0.1311, -0.1241],\r\n",
      "        ...,\r\n",
      "        [-0.1441,  0.1212,  0.0464,  ...,  0.0980, -0.1064,  0.0074],\r\n",
      "        [-0.0442,  0.0230,  0.1446,  ..., -0.0268, -0.0975,  0.1295],\r\n",
      "        [ 0.0011, -0.0090, -0.0276,  ..., -0.0270,  0.1067,  0.0041]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:41:24,514 (client:259)INFO: {'Role': 'Client #7', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.685713, 'train_acc': 0.558348, 'train_loss': 1527.768891, 'train_imp_ratio': -46.05947, 'train_total': 2228}}\r\n",
      "before train name: gnn.convs.1.nn.linears.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0112,  0.0720, -0.0167,  ...,  0.0234, -0.0093, -0.1161],\r\n",
      "        [ 0.1189,  0.1219, -0.0094,  ..., -0.0474, -0.0282,  0.0653],\r\n",
      "        [ 0.1079, -0.0408,  0.1248,  ..., -0.0096,  0.0366,  0.0723],\r\n",
      "        ...,\r\n",
      "        [-0.0006, -0.0216,  0.0949,  ...,  0.0612, -0.1049,  0.0126],\r\n",
      "        [-0.0736,  0.0794,  0.0823,  ...,  0.0652, -0.0878,  0.0645],\r\n",
      "        [ 0.0330,  0.0718, -0.0751,  ...,  0.0717,  0.0238,  0.0704]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:41:24,620 (client:259)INFO: {'Role': 'Client #12', 'Round': 0, 'Results_raw': {'train_avg_loss': 13.410168, 'train_imp_ratio': -885.081218, 'train_total': 608, 'train_loss': 8153.381897}}\r\n",
      "before train name: gnn.convs.1.nn.norms.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\r\n",
      "2022-09-13 12:41:24,655 (client:259)INFO: {'Role': 'Client #5', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.693967, 'train_acc': 0.5, 'train_loss': 130.465708, 'train_imp_ratio': -26.000126, 'train_total': 188}}\r\n",
      "before train name: gnn.convs.1.nn.linears.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0112,  0.0720, -0.0167,  ...,  0.0234, -0.0093, -0.1161],\r\n",
      "        [ 0.1189,  0.1219, -0.0094,  ..., -0.0474, -0.0282,  0.0653],\r\n",
      "        [ 0.1079, -0.0408,  0.1248,  ..., -0.0096,  0.0366,  0.0723],\r\n",
      "        ...,\r\n",
      "        [-0.0006, -0.0216,  0.0949,  ...,  0.0612, -0.1049,  0.0126],\r\n",
      "        [-0.0736,  0.0794,  0.0823,  ...,  0.0652, -0.0878,  0.0645],\r\n",
      "        [ 0.0330,  0.0718, -0.0751,  ...,  0.0717,  0.0238,  0.0704]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:41:25,082 (client:259)INFO: {'Role': 'Client #11', 'Round': 0, 'Results_raw': {'train_avg_loss': 2.491096, 'train_imp_ratio': -239.381293, 'train_total': 2268, 'train_loss': 5649.805989}}\r\n",
      "before train name: encoder_atom.atom_embedding_list.34.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[ 0.0851,  0.0411, -0.1064,  ...,  0.0810,  0.1245, -0.1286],\r\n",
      "        [ 0.0065,  0.0085, -0.0363,  ..., -0.0013,  0.0342,  0.0648],\r\n",
      "        [-0.0205,  0.0026, -0.0734,  ..., -0.0167, -0.0709,  0.0040],\r\n",
      "        ...,\r\n",
      "        [-0.0602,  0.0632, -0.0266,  ...,  0.1395,  0.0952,  0.0826],\r\n",
      "        [-0.0770, -0.0289,  0.0970,  ..., -0.1387,  0.0327,  0.1151],\r\n",
      "        [-0.0940, -0.1004, -0.0576,  ..., -0.1122,  0.0332, -0.0555]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:41:25,493 (client:259)INFO: {'Role': 'Client #3', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.700647, 'train_acc': 0.459667, 'train_loss': 1554.735559, 'train_imp_ratio': -52.033597, 'train_total': 2219}}\r\n",
      "before train name: gnn.convs.0.nn.norms.0.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\r\n",
      "2022-09-13 12:41:47,997 (client:259)INFO: {'Role': 'Client #9', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.054579, 'train_imp_ratio': 7.803826, 'train_total': 134706, 'train_loss': 7352.147535}}\r\n",
      "before train name: gnn.convs.1.nn.norms.0.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\r\n",
      "2022-09-13 12:41:48,031 (client:259)INFO: {'Role': 'Client #2', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.681369, 'train_acc': 0.59116, 'train_loss': 123.327852, 'train_imp_ratio': -41.16567, 'train_total': 181}}\r\n",
      "before train name: gnn.convs.1.nn.norms.0.bias\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\r\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:41:48,159 (client:259)INFO: {'Role': 'Client #8', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.524714, 'train_imp_ratio': 21.51615, 'train_total': 777, 'train_loss': 407.703133}}\r\n",
      "2022-09-13 12:42:03,956 (client:259)INFO: {'Role': 'Client #10', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.008204, 'train_imp_ratio': -15.823499, 'train_total': 109392, 'train_loss': 897.427672}}\r\n",
      "2022-09-13 12:42:03,979 (client:259)INFO: {'Role': 'Client #4', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.67156, 'train_acc': 0.653465, 'train_loss': 67.827588, 'train_imp_ratio': -96.369179, 'train_total': 101}}\r\n",
      "before train name: gnn.convs.1.nn.linears.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0112,  0.0720, -0.0167,  ...,  0.0234, -0.0093, -0.1161],\r\n",
      "        [ 0.1189,  0.1219, -0.0094,  ..., -0.0474, -0.0282,  0.0653],\r\n",
      "        [ 0.1079, -0.0408,  0.1248,  ..., -0.0096,  0.0366,  0.0723],\r\n",
      "        ...,\r\n",
      "        [-0.0006, -0.0216,  0.0949,  ...,  0.0612, -0.1049,  0.0126],\r\n",
      "        [-0.0736,  0.0794,  0.0823,  ...,  0.0652, -0.0878,  0.0645],\r\n",
      "        [ 0.0330,  0.0718, -0.0751,  ...,  0.0717,  0.0238,  0.0704]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:42:04,229 (client:259)INFO: {'Role': 'Client #1', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.630581, 'train_acc': 0.640512, 'train_loss': 787.595967, 'train_imp_ratio': -36.278461, 'train_total': 1249}}\r\n",
      "before train name: gnn.convs.1.nn.linears.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0112,  0.0720, -0.0167,  ...,  0.0234, -0.0093, -0.1161],\r\n",
      "        [ 0.1189,  0.1219, -0.0094,  ..., -0.0474, -0.0282,  0.0653],\r\n",
      "        [ 0.1079, -0.0408,  0.1248,  ..., -0.0096,  0.0366,  0.0723],\r\n",
      "        ...,\r\n",
      "        [-0.0006, -0.0216,  0.0949,  ...,  0.0612, -0.1049,  0.0126],\r\n",
      "        [-0.0736,  0.0794,  0.0823,  ...,  0.0652, -0.0878,  0.0645],\r\n",
      "        [ 0.0330,  0.0718, -0.0751,  ...,  0.0717,  0.0238,  0.0704]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:42:04,434 (client:259)INFO: {'Role': 'Client #6', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.703967, 'train_acc': 0.348774, 'train_loss': 775.067432, 'train_imp_ratio': -148.958696, 'train_total': 1101}}\r\n",
      "2022-09-13 12:42:15,777 (client:259)INFO: {'Role': 'Client #13', 'Round': 0, 'Results_raw': {'train_avg_loss': 0.007168, 'train_imp_ratio': -63.321588, 'train_total': 70648, 'train_loss': 506.417838}}\r\n",
      "2022-09-13 12:42:15,784 (server:316)INFO: Server #0: Starting evaluation at the end of round 0.\r\n",
      "2022-09-13 12:42:15,785 (server:323)INFO: ----------- Starting a new training round (Round #1) -------------\r\n",
      "before train name: gnn.convs.1.nn.linears.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0078,  0.0607, -0.0127,  ...,  0.0169, -0.0110, -0.1088],\r\n",
      "        [ 0.1072,  0.1107, -0.0051,  ..., -0.0374, -0.0308,  0.0563],\r\n",
      "        [ 0.1071, -0.0187,  0.1249,  ...,  0.0179,  0.0243,  0.0743],\r\n",
      "        ...,\r\n",
      "        [ 0.0014, -0.0079,  0.0910,  ...,  0.0654, -0.0950,  0.0187],\r\n",
      "        [-0.0614,  0.0781,  0.0788,  ...,  0.0645, -0.0791,  0.0595],\r\n",
      "        [ 0.0366,  0.0729, -0.0601,  ...,  0.0797,  0.0119,  0.0715]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:42:38,004 (client:259)INFO: {'Role': 'Client #6', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.729661, 'train_acc': 0.26703, 'train_loss': 803.356464, 'train_imp_ratio': -180.208742, 'train_total': 1101}}\r\n",
      "before train name: encoder_atom.atom_embedding_list.34.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[ 0.0851,  0.0411, -0.1064,  ...,  0.0810,  0.1245, -0.1286],\r\n",
      "        [ 0.0065,  0.0085, -0.0363,  ..., -0.0013,  0.0342,  0.0648],\r\n",
      "        [-0.0205,  0.0026, -0.0734,  ..., -0.0167, -0.0709,  0.0040],\r\n",
      "        ...,\r\n",
      "        [-0.0602,  0.0632, -0.0266,  ...,  0.1395,  0.0952,  0.0826],\r\n",
      "        [-0.0770, -0.0289,  0.0970,  ..., -0.1387,  0.0327,  0.1151],\r\n",
      "        [-0.0940, -0.1004, -0.0576,  ..., -0.1122,  0.0332, -0.0555]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:42:38,415 (client:259)INFO: {'Role': 'Client #3', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.69623, 'train_acc': 0.471384, 'train_loss': 1544.934447, 'train_imp_ratio': -48.736788, 'train_total': 2219}}\r\n",
      "2022-09-13 12:42:38,445 (client:259)INFO: {'Role': 'Client #4', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.670235, 'train_acc': 0.653465, 'train_loss': 67.693733, 'train_imp_ratio': -96.369179, 'train_total': 101}}\r\n",
      "before train name: gnn.convs.1.nn.norms.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\r\n",
      "2022-09-13 12:42:38,480 (client:259)INFO: {'Role': 'Client #5', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.695713, 'train_acc': 0.484043, 'train_loss': 130.794036, 'train_imp_ratio': -30.021407, 'train_total': 188}}\r\n",
      "before train name: gnn.convs.1.nn.linears.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0078,  0.0607, -0.0127,  ...,  0.0169, -0.0110, -0.1088],\r\n",
      "        [ 0.1072,  0.1107, -0.0051,  ..., -0.0374, -0.0308,  0.0563],\r\n",
      "        [ 0.1071, -0.0187,  0.1249,  ...,  0.0179,  0.0243,  0.0743],\r\n",
      "        ...,\r\n",
      "        [ 0.0014, -0.0079,  0.0910,  ...,  0.0654, -0.0950,  0.0187],\r\n",
      "        [-0.0614,  0.0781,  0.0788,  ...,  0.0645, -0.0791,  0.0595],\r\n",
      "        [ 0.0366,  0.0729, -0.0601,  ...,  0.0797,  0.0119,  0.0715]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:42:38,578 (client:259)INFO: {'Role': 'Client #12', 'Round': 1, 'Results_raw': {'train_avg_loss': 13.303309, 'train_imp_ratio': -877.231717, 'train_total': 608, 'train_loss': 8088.411987}}\r\n",
      "before train name: gnn.convs.1.nn.linears.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0078,  0.0607, -0.0127,  ...,  0.0169, -0.0110, -0.1088],\r\n",
      "        [ 0.1072,  0.1107, -0.0051,  ..., -0.0374, -0.0308,  0.0563],\r\n",
      "        [ 0.1071, -0.0187,  0.1249,  ...,  0.0179,  0.0243,  0.0743],\r\n",
      "        ...,\r\n",
      "        [ 0.0014, -0.0079,  0.0910,  ...,  0.0654, -0.0950,  0.0187],\r\n",
      "        [-0.0614,  0.0781,  0.0788,  ...,  0.0645, -0.0791,  0.0595],\r\n",
      "        [ 0.0366,  0.0729, -0.0601,  ...,  0.0797,  0.0119,  0.0715]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:42:38,826 (client:259)INFO: {'Role': 'Client #1', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.621174, 'train_acc': 0.640512, 'train_loss': 775.845904, 'train_imp_ratio': -36.278461, 'train_total': 1249}}\r\n",
      "2022-09-13 12:42:54,192 (client:259)INFO: {'Role': 'Client #10', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.006778, 'train_imp_ratio': 4.304653, 'train_total': 109392, 'train_loss': 741.470014}}\r\n",
      "2022-09-13 12:43:05,528 (client:259)INFO: {'Role': 'Client #13', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.005062, 'train_imp_ratio': -15.343314, 'train_total': 70648, 'train_loss': 357.649681}}\r\n",
      "before train name: gnn.convs.1.nn.norms.0.bias\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([ 1.4834e-03, -5.1643e-03,  1.9846e-02, -2.5597e-02,  5.9893e-03,\r\n",
      "        -1.3176e-02, -7.0379e-03,  7.2731e-04, -1.6191e-03,  5.9816e-04,\r\n",
      "        -5.2681e-03, -7.7903e-03, -1.2963e-02, -6.4807e-03,  2.1763e-03,\r\n",
      "         1.0883e-02, -8.5343e-03, -3.9079e-03,  5.3879e-03, -3.6293e-03,\r\n",
      "        -4.3143e-03,  1.6492e-03,  1.0402e-02,  9.8745e-03, -1.3631e-05,\r\n",
      "        -1.2846e-02, -1.0771e-02, -3.9668e-03, -1.7444e-03,  7.5522e-03,\r\n",
      "        -2.9465e-03, -5.1765e-03, -2.0804e-03, -1.4318e-02, -1.0023e-02,\r\n",
      "        -4.2470e-03,  3.6484e-04, -1.0892e-02, -4.7123e-03, -3.1483e-03,\r\n",
      "        -3.6058e-04, -5.9656e-03,  4.0972e-03, -6.7438e-03, -3.9080e-03,\r\n",
      "         1.0131e-02, -7.4679e-03,  3.0987e-03,  6.8569e-03, -1.7547e-03,\r\n",
      "        -3.9556e-03, -8.8904e-04,  4.4313e-04, -1.8881e-03, -6.5171e-03,\r\n",
      "         1.4444e-02,  1.0891e-02, -6.4974e-04,  7.2542e-03,  8.0997e-03,\r\n",
      "        -5.0752e-04, -2.3185e-03, -1.8474e-03,  2.1156e-03],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:43:05,654 (client:259)INFO: {'Role': 'Client #8', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.460618, 'train_imp_ratio': 21.51615, 'train_total': 777, 'train_loss': 357.899862}}\r\n",
      "before train name: encoder_atom.atom_embedding_list.34.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0550, -0.0620,  0.0381,  ...,  0.0264, -0.0695, -0.1250],\r\n",
      "        [-0.0690,  0.1212, -0.0542,  ...,  0.0780,  0.1470,  0.0069],\r\n",
      "        [ 0.1111, -0.0047,  0.0179,  ...,  0.0364, -0.1311, -0.1241],\r\n",
      "        ...,\r\n",
      "        [-0.1441,  0.1212,  0.0464,  ...,  0.0980, -0.1064,  0.0074],\r\n",
      "        [-0.0442,  0.0230,  0.1446,  ..., -0.0268, -0.0975,  0.1295],\r\n",
      "        [ 0.0011, -0.0090, -0.0276,  ..., -0.0270,  0.1067,  0.0041]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:43:06,060 (client:259)INFO: {'Role': 'Client #7', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.680617, 'train_acc': 0.564632, 'train_loss': 1516.414977, 'train_imp_ratio': -43.981389, 'train_total': 2228}}\r\n",
      "before train name: gnn.convs.1.nn.norms.0.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([0.8863, 0.8851, 0.8955, 0.8996, 0.8816, 0.8957, 0.8782, 0.8835, 0.8827,\r\n",
      "        0.8849, 0.8819, 0.8793, 0.8837, 0.8791, 0.8900, 0.8936, 0.8809, 0.8797,\r\n",
      "        0.8933, 0.8817, 0.8797, 0.8840, 0.8893, 0.8814, 0.8833, 0.8919, 0.8905,\r\n",
      "        0.8844, 0.8817, 0.9014, 0.8799, 0.8773, 0.8871, 0.8766, 0.8822, 0.8852,\r\n",
      "        0.8811, 0.8963, 0.8826, 0.8996, 0.8820, 0.8858, 0.8832, 0.8828, 0.8796,\r\n",
      "        0.8947, 0.8790, 0.8871, 0.8930, 0.8887, 0.8823, 0.8817, 0.8832, 0.8820,\r\n",
      "        0.8806, 0.8842, 0.8892, 0.8831, 0.8831, 0.8817, 0.8991, 0.8983, 0.8813,\r\n",
      "        0.8847], requires_grad=True)\r\n",
      "2022-09-13 12:43:06,094 (client:259)INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.681756, 'train_acc': 0.59116, 'train_loss': 123.397769, 'train_imp_ratio': -41.16567, 'train_total': 181}}\r\n",
      "before train name: gnn.convs.1.nn.linears.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0078,  0.0607, -0.0127,  ...,  0.0169, -0.0110, -0.1088],\r\n",
      "        [ 0.1072,  0.1107, -0.0051,  ..., -0.0374, -0.0308,  0.0563],\r\n",
      "        [ 0.1071, -0.0187,  0.1249,  ...,  0.0179,  0.0243,  0.0743],\r\n",
      "        ...,\r\n",
      "        [ 0.0014, -0.0079,  0.0910,  ...,  0.0654, -0.0950,  0.0187],\r\n",
      "        [-0.0614,  0.0781,  0.0788,  ...,  0.0645, -0.0791,  0.0595],\r\n",
      "        [ 0.0366,  0.0729, -0.0601,  ...,  0.0797,  0.0119,  0.0715]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:43:06,514 (client:259)INFO: {'Role': 'Client #11', 'Round': 1, 'Results_raw': {'train_avg_loss': 1.629916, 'train_imp_ratio': -122.056099, 'train_total': 2268, 'train_loss': 3696.649999}}\r\n",
      "before train name: gnn.convs.0.nn.norms.0.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([0.8820, 0.8859, 0.8774, 0.8844, 0.8832, 0.8765, 0.8789, 0.8812, 0.8812,\r\n",
      "        0.8791, 0.8827, 0.8798, 0.8844, 0.8833, 0.8815, 0.8795, 0.8803, 0.8925,\r\n",
      "        0.9022, 0.8874, 0.8824, 0.8811, 0.8827, 0.8833, 0.8794, 0.8871, 0.8776,\r\n",
      "        0.8818, 0.8812, 0.8817, 0.8815, 0.8807, 0.8833, 0.8793, 0.8848, 0.8783,\r\n",
      "        0.8824, 0.8796, 0.8786, 0.8844, 0.8832, 0.8841, 0.8775, 0.8799, 0.8829,\r\n",
      "        0.8837, 0.8886, 0.8823, 0.8809, 0.8847, 0.8796, 0.8785, 0.8841, 0.8822,\r\n",
      "        0.8872, 0.8774, 0.8889, 0.8799, 0.8823, 0.8812, 0.8817, 0.8796, 0.8790,\r\n",
      "        0.8825], requires_grad=True)\r\n",
      "2022-09-13 12:43:29,193 (client:259)INFO: {'Role': 'Client #9', 'Round': 1, 'Results_raw': {'train_avg_loss': 0.045609, 'train_imp_ratio': 22.956278, 'train_total': 134706, 'train_loss': 6143.8212}}\r\n",
      "2022-09-13 12:43:29,195 (server:489)INFO: {'Role': 'Server #', 'Round': 1, 'Results_avg': {'test_avg_loss': 0.703139, 'test_acc': 0.714286, 'test_loss': 9065.367984, 'test_imp_ratio': -1147.967251, 'test_total': 8350.846154, 'val_avg_loss': 1.836626, 'val_acc': 0.522316, 'val_loss': 1298.784185, 'val_imp_ratio': -319.628979, 'val_total': 8350.461538}}\r\n",
      "2022-09-13 12:43:29,202 (server:316)INFO: Server #0: Starting evaluation at the end of round 1.\r\n",
      "2022-09-13 12:43:29,202 (server:323)INFO: ----------- Starting a new training round (Round #2) -------------\r\n",
      "before train name: gnn.convs.1.nn.linears.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0042,  0.0546, -0.0061,  ...,  0.0171, -0.0108, -0.0991],\r\n",
      "        [ 0.0980,  0.1019, -0.0005,  ..., -0.0298, -0.0327,  0.0506],\r\n",
      "        [ 0.1058, -0.0084,  0.1196,  ...,  0.0289,  0.0102,  0.0735],\r\n",
      "        ...,\r\n",
      "        [ 0.0070, -0.0003,  0.0853,  ...,  0.0663, -0.0895,  0.0219],\r\n",
      "        [-0.0545,  0.0707,  0.0709,  ...,  0.0567, -0.0719,  0.0528],\r\n",
      "        [ 0.0388,  0.0684, -0.0510,  ...,  0.0788,  0.0004,  0.0697]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:43:51,518 (client:259)INFO: {'Role': 'Client #11', 'Round': 2, 'Results_raw': {'train_avg_loss': 1.478069, 'train_imp_ratio': -101.368855, 'train_total': 2268, 'train_loss': 3352.26162}}\r\n",
      "before train name: gnn.convs.1.nn.norms.0.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([0.7884, 0.7836, 0.8024, 0.8133, 0.7782, 0.8069, 0.7728, 0.7791, 0.7801,\r\n",
      "        0.7827, 0.7795, 0.7741, 0.7817, 0.7739, 0.7928, 0.7974, 0.7816, 0.7785,\r\n",
      "        0.7989, 0.7799, 0.7741, 0.7801, 0.7944, 0.7783, 0.7810, 0.8014, 0.7948,\r\n",
      "        0.7859, 0.7789, 0.8152, 0.7744, 0.7701, 0.7877, 0.7707, 0.7801, 0.7865,\r\n",
      "        0.7759, 0.8104, 0.7851, 0.8121, 0.7788, 0.7867, 0.7803, 0.7839, 0.7762,\r\n",
      "        0.8017, 0.7728, 0.7844, 0.7988, 0.8005, 0.7786, 0.7768, 0.7786, 0.7825,\r\n",
      "        0.7748, 0.7824, 0.7894, 0.7814, 0.7813, 0.7766, 0.8092, 0.8042, 0.7776,\r\n",
      "        0.7833], requires_grad=True)\r\n",
      "2022-09-13 12:43:51,552 (client:259)INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.681682, 'train_acc': 0.59116, 'train_loss': 123.384502, 'train_imp_ratio': -41.16567, 'train_total': 181}}\r\n",
      "before train name: encoder_atom.atom_embedding_list.34.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0550, -0.0620,  0.0381,  ...,  0.0264, -0.0695, -0.1250],\r\n",
      "        [-0.0690,  0.1212, -0.0542,  ...,  0.0780,  0.1470,  0.0069],\r\n",
      "        [ 0.1111, -0.0047,  0.0179,  ...,  0.0364, -0.1311, -0.1241],\r\n",
      "        ...,\r\n",
      "        [-0.1441,  0.1212,  0.0464,  ...,  0.0980, -0.1064,  0.0074],\r\n",
      "        [-0.0442,  0.0230,  0.1446,  ..., -0.0268, -0.0975,  0.1295],\r\n",
      "        [ 0.0011, -0.0090, -0.0276,  ..., -0.0270,  0.1067,  0.0041]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:43:51,988 (client:259)INFO: {'Role': 'Client #7', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.681219, 'train_acc': 0.554758, 'train_loss': 1517.755921, 'train_imp_ratio': -47.246946, 'train_total': 2228}}\r\n",
      "before train name: gnn.convs.1.nn.norms.0.bias\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([ 0.0017, -0.0094,  0.0319, -0.0473,  0.0105, -0.0187, -0.0086, -0.0025,\r\n",
      "        -0.0051,  0.0043, -0.0086, -0.0163, -0.0301, -0.0089,  0.0009,  0.0157,\r\n",
      "        -0.0079, -0.0031, -0.0041, -0.0035, -0.0113,  0.0006,  0.0146,  0.0035,\r\n",
      "        -0.0030, -0.0194, -0.0168, -0.0069, -0.0052,  0.0128, -0.0085, -0.0093,\r\n",
      "        -0.0070, -0.0218, -0.0156,  0.0008, -0.0010, -0.0146, -0.0202, -0.0116,\r\n",
      "        -0.0007, -0.0046,  0.0026, -0.0176, -0.0052,  0.0205, -0.0150,  0.0032,\r\n",
      "         0.0015,  0.0022, -0.0102, -0.0045, -0.0059, -0.0030, -0.0096,  0.0228,\r\n",
      "         0.0127, -0.0024,  0.0084,  0.0072, -0.0042, -0.0084, -0.0014, -0.0009],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:43:52,113 (client:259)INFO: {'Role': 'Client #8', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.450459, 'train_imp_ratio': 21.51615, 'train_total': 777, 'train_loss': 350.006625}}\r\n",
      "before train name: encoder_atom.atom_embedding_list.34.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[ 0.0851,  0.0411, -0.1064,  ...,  0.0810,  0.1245, -0.1286],\r\n",
      "        [ 0.0065,  0.0085, -0.0363,  ..., -0.0013,  0.0342,  0.0648],\r\n",
      "        [-0.0205,  0.0026, -0.0734,  ..., -0.0167, -0.0709,  0.0040],\r\n",
      "        ...,\r\n",
      "        [-0.0602,  0.0632, -0.0266,  ...,  0.1395,  0.0952,  0.0826],\r\n",
      "        [-0.0770, -0.0289,  0.0970,  ..., -0.1387,  0.0327,  0.1151],\r\n",
      "        [-0.0940, -0.1004, -0.0576,  ..., -0.1122,  0.0332, -0.0555]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:43:52,524 (client:259)INFO: {'Role': 'Client #3', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.695328, 'train_acc': 0.467778, 'train_loss': 1542.932763, 'train_imp_ratio': -49.751191, 'train_total': 2219}}\r\n",
      "2022-09-13 12:44:03,774 (client:259)INFO: {'Role': 'Client #13', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.004769, 'train_imp_ratio': -8.659626, 'train_total': 70648, 'train_loss': 336.925372}}\r\n",
      "before train name: gnn.convs.1.nn.linears.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0042,  0.0546, -0.0061,  ...,  0.0171, -0.0108, -0.0991],\r\n",
      "        [ 0.0980,  0.1019, -0.0005,  ..., -0.0298, -0.0327,  0.0506],\r\n",
      "        [ 0.1058, -0.0084,  0.1196,  ...,  0.0289,  0.0102,  0.0735],\r\n",
      "        ...,\r\n",
      "        [ 0.0070, -0.0003,  0.0853,  ...,  0.0663, -0.0895,  0.0219],\r\n",
      "        [-0.0545,  0.0707,  0.0709,  ...,  0.0567, -0.0719,  0.0528],\r\n",
      "        [ 0.0388,  0.0684, -0.0510,  ...,  0.0788,  0.0004,  0.0697]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:44:03,977 (client:259)INFO: {'Role': 'Client #6', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.728721, 'train_acc': 0.26703, 'train_loss': 802.322135, 'train_imp_ratio': -180.208742, 'train_total': 1101}}\r\n",
      "before train name: gnn.convs.1.nn.linears.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0042,  0.0546, -0.0061,  ...,  0.0171, -0.0108, -0.0991],\r\n",
      "        [ 0.0980,  0.1019, -0.0005,  ..., -0.0298, -0.0327,  0.0506],\r\n",
      "        [ 0.1058, -0.0084,  0.1196,  ...,  0.0289,  0.0102,  0.0735],\r\n",
      "        ...,\r\n",
      "        [ 0.0070, -0.0003,  0.0853,  ...,  0.0663, -0.0895,  0.0219],\r\n",
      "        [-0.0545,  0.0707,  0.0709,  ...,  0.0567, -0.0719,  0.0528],\r\n",
      "        [ 0.0388,  0.0684, -0.0510,  ...,  0.0788,  0.0004,  0.0697]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:44:04,071 (client:259)INFO: {'Role': 'Client #12', 'Round': 2, 'Results_raw': {'train_avg_loss': 12.651505, 'train_imp_ratio': -829.351637, 'train_total': 608, 'train_loss': 7692.115051}}\r\n",
      "before train name: gnn.convs.1.nn.linears.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([[-0.0042,  0.0546, -0.0061,  ...,  0.0171, -0.0108, -0.0991],\r\n",
      "        [ 0.0980,  0.1019, -0.0005,  ..., -0.0298, -0.0327,  0.0506],\r\n",
      "        [ 0.1058, -0.0084,  0.1196,  ...,  0.0289,  0.0102,  0.0735],\r\n",
      "        ...,\r\n",
      "        [ 0.0070, -0.0003,  0.0853,  ...,  0.0663, -0.0895,  0.0219],\r\n",
      "        [-0.0545,  0.0707,  0.0709,  ...,  0.0567, -0.0719,  0.0528],\r\n",
      "        [ 0.0388,  0.0684, -0.0510,  ...,  0.0788,  0.0004,  0.0697]],\r\n",
      "       requires_grad=True)\r\n",
      "2022-09-13 12:44:04,328 (client:259)INFO: {'Role': 'Client #1', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.622784, 'train_acc': 0.641313, 'train_loss': 777.85716, 'train_imp_ratio': -35.974946, 'train_total': 1249}}\r\n",
      "2022-09-13 12:44:04,350 (client:259)INFO: {'Role': 'Client #4', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.671115, 'train_acc': 0.653465, 'train_loss': 67.782648, 'train_imp_ratio': -96.369179, 'train_total': 101}}\r\n",
      "before train name: gnn.convs.1.nn.norms.1.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\r\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\r\n",
      "2022-09-13 12:44:04,386 (client:259)INFO: {'Role': 'Client #5', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.693902, 'train_acc': 0.5, 'train_loss': 130.453522, 'train_imp_ratio': -26.000126, 'train_total': 188}}\r\n",
      "2022-09-13 12:44:19,899 (client:259)INFO: {'Role': 'Client #10', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.006625, 'train_imp_ratio': 6.466313, 'train_total': 109392, 'train_loss': 724.721063}}\r\n",
      "before train name: gnn.convs.0.nn.norms.0.weight\r\n",
      "before train param: Parameter containing:\r\n",
      "tensor([0.7791, 0.7816, 0.7676, 0.7833, 0.7805, 0.7675, 0.7737, 0.7764, 0.7772,\r\n",
      "        0.7743, 0.7787, 0.7761, 0.7806, 0.7798, 0.7771, 0.7751, 0.7740, 0.7954,\r\n",
      "        0.8074, 0.7859, 0.7785, 0.7771, 0.7765, 0.7791, 0.7725, 0.7861, 0.7719,\r\n",
      "        0.7752, 0.7769, 0.7771, 0.7750, 0.7754, 0.7809, 0.7753, 0.7819, 0.7730,\r\n",
      "        0.7807, 0.7749, 0.7716, 0.7798, 0.7783, 0.7806, 0.7717, 0.7739, 0.7791,\r\n",
      "        0.7804, 0.7870, 0.7786, 0.7761, 0.7843, 0.7738, 0.7770, 0.7834, 0.7843,\r\n",
      "        0.7886, 0.7690, 0.7872, 0.7747, 0.7774, 0.7775, 0.7772, 0.7754, 0.7745,\r\n",
      "        0.7789], requires_grad=True)\r\n",
      "2022-09-13 12:44:42,567 (client:259)INFO: {'Role': 'Client #9', 'Round': 2, 'Results_raw': {'train_avg_loss': 0.044152, 'train_imp_ratio': 25.417975, 'train_total': 134706, 'train_loss': 5947.513612}}\r\n",
      "2022-09-13 12:44:42,568 (server:489)INFO: {'Role': 'Server #', 'Round': 2, 'Results_avg': {'test_avg_loss': 0.868307, 'test_acc': 0.708813, 'test_loss': 13410.232806, 'test_imp_ratio': -1644.703326, 'test_total': 8350.846154, 'val_avg_loss': 1.70889, 'val_acc': 0.534235, 'val_loss': 1576.792165, 'val_imp_ratio': -355.443447, 'val_total': 8350.461538}}\r\n",
      "2022-09-13 12:44:42,574 (server:334)INFO: Server #0: Training is finished! Starting evaluation.\r\n",
      "2022-09-13 12:45:03,618 (server:489)INFO: {'Role': 'Server #', 'Round': 3, 'Results_avg': {'test_avg_loss': 0.866683, 'test_acc': 0.715453, 'test_loss': 12569.560393, 'test_imp_ratio': -1466.81867, 'test_total': 8350.846154, 'val_avg_loss': 1.644571, 'val_acc': 0.543519, 'val_loss': 1409.991884, 'val_imp_ratio': -291.17557, 'val_total': 8350.461538}}\r\n",
      "2022-09-13 12:45:03,618 (server:388)INFO: Server #0: Final evaluation is finished! Starting merging results.\r\n",
      "2022-09-13 12:45:03,618 (server:418)INFO: {'Role': 'Server #', 'Round': 'Final', 'Results_raw': {'client_best_individual': {}, 'client_summarized_avg': {}}}\r\n",
      "2022-09-13 12:45:03,618 (server:439)INFO: {'Role': 'Client #1', 'Round': 3, 'Results_raw': {'test_avg_loss': 0.415799, 'test_acc': 1.0, 'test_loss': 173.388153, 'test_imp_ratio': 100.0, 'test_total': 417, 'val_avg_loss': 0.669803, 'val_acc': 0.615385, 'val_loss': 278.637938, 'val_imp_ratio': -45.804179, 'val_total': 416}}\r\n",
      "2022-09-13 12:45:03,619 (server:439)INFO: {'Role': 'Client #2', 'Round': 3, 'Results_raw': {'test_avg_loss': 0.488441, 'test_acc': 1.0, 'test_loss': 29.79493, 'test_imp_ratio': 100.0, 'test_total': 61, 'val_avg_loss': 0.684512, 'val_acc': 0.583333, 'val_loss': 41.070735, 'val_imp_ratio': -43.868166, 'val_total': 60}}\r\n",
      "2022-09-13 12:45:03,619 (server:439)INFO: {'Role': 'Client #3', 'Round': 3, 'Results_raw': {'test_avg_loss': 0.786288, 'test_acc': 0.0, 'test_loss': 581.853018, 'test_imp_ratio': -181.369934, 'test_total': 740, 'val_avg_loss': 0.706365, 'val_acc': 0.439189, 'val_loss': 522.710242, 'val_imp_ratio': -57.795301, 'val_total': 740}}\r\n",
      "2022-09-13 12:45:03,619 (server:439)INFO: {'Role': 'Client #4', 'Round': 3, 'Results_raw': {'test_avg_loss': 0.608506, 'test_acc': 1.0, 'test_loss': 20.689207, 'test_imp_ratio': 100.0, 'test_total': 34, 'val_avg_loss': 0.730223, 'val_acc': 0.323529, 'val_loss': 24.827595, 'val_imp_ratio': -283.332439, 'val_total': 34}}\r\n",
      "2022-09-13 12:45:03,619 (server:439)INFO: {'Role': 'Client #5', 'Round': 3, 'Results_raw': {'test_avg_loss': 0.636892, 'test_acc': 1.0, 'test_loss': 40.124168, 'test_imp_ratio': 100.0, 'test_total': 63, 'val_avg_loss': 0.691962, 'val_acc': 0.555556, 'val_loss': 43.593619, 'val_imp_ratio': -12.000112, 'val_total': 63}}\r\n",
      "2022-09-13 12:45:03,619 (server:439)INFO: {'Role': 'Client #6', 'Round': 3, 'Results_raw': {'test_avg_loss': 0.720335, 'test_acc': 0.008174, 'test_loss': 264.363006, 'test_imp_ratio': -279.16722, 'test_total': 367, 'val_avg_loss': 0.680563, 'val_acc': 0.746594, 'val_loss': 249.766522, 'val_imp_ratio': 3.124859, 'val_total': 367}}\r\n",
      "2022-09-13 12:45:03,620 (server:439)INFO: {'Role': 'Client #7', 'Round': 3, 'Results_raw': {'test_avg_loss': 0.602876, 'test_acc': 1.0, 'test_loss': 447.937202, 'test_imp_ratio': 100.0, 'test_total': 743, 'val_avg_loss': 0.689783, 'val_acc': 0.54105, 'val_loss': 512.509106, 'val_imp_ratio': -51.780289, 'val_total': 743}}\r\n",
      "2022-09-13 12:45:03,620 (server:439)INFO: {'Role': 'Client #8', 'Round': 3, 'Results_raw': {'test_avg_loss': 2.183594, 'test_imp_ratio': -372.728304, 'test_total': 260, 'test_loss': 567.734346, 'val_avg_loss': 0.393131, 'val_imp_ratio': 37.943003, 'val_total': 259, 'val_loss': 101.820996}}\r\n",
      "2022-09-13 12:45:03,620 (server:439)INFO: {'Role': 'Client #9', 'Round': 3, 'Results_raw': {'test_avg_loss': 3.206109, 'test_imp_ratio': -5315.816628, 'test_total': 44902, 'test_loss': 143960.721556, 'val_avg_loss': 0.196886, 'val_imp_ratio': -232.583502, 'val_total': 44902, 'val_loss': 8840.579649}}\r\n",
      "2022-09-13 12:45:03,620 (server:439)INFO: {'Role': 'Client #10', 'Round': 3, 'Results_raw': {'test_avg_loss': 0.115026, 'test_imp_ratio': -1523.970644, 'test_total': 36465, 'test_loss': 4194.418263, 'val_avg_loss': 0.024114, 'val_imp_ratio': -240.455427, 'val_total': 36464, 'val_loss': 879.309489}}\r\n",
      "2022-09-13 12:45:03,620 (server:439)INFO: {'Role': 'Client #11', 'Round': 3, 'Results_raw': {'test_avg_loss': 0.807454, 'test_imp_ratio': -10.005723, 'test_total': 756, 'test_loss': 610.435255, 'val_avg_loss': 3.192445, 'val_imp_ratio': -334.931433, 'val_total': 756, 'val_loss': 2413.488096}}\r\n",
      "2022-09-13 12:45:03,621 (server:439)INFO: {'Role': 'Client #12', 'Round': 3, 'Results_raw': {'test_avg_loss': 0.165652, 'test_imp_ratio': 87.831548, 'test_total': 203, 'test_loss': 33.627416, 'val_avg_loss': 12.640847, 'val_imp_ratio': -828.568705, 'val_total': 203, 'val_loss': 2566.092036}}\r\n",
      "2022-09-13 12:45:03,621 (server:439)INFO: {'Role': 'Client #13', 'Round': 3, 'Results_raw': {'test_avg_loss': 0.529902, 'test_imp_ratio': -11973.415807, 'test_total': 23550, 'test_loss': 12479.198594, 'val_avg_loss': 0.078793, 'val_imp_ratio': -1695.230721, 'val_total': 23549, 'val_loss': 1855.488468}}\r\n",
      "2022-09-13 12:45:03,621 (monitor:121)INFO: In worker #0, the system-related metrics are: {'id': 0, 'fl_end_time_minutes': 3.662495, 'total_model_size': 0, 'total_flops': 0, 'total_upload_bytes': 1592448, 'total_download_bytes': 416216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:03,622 (client:440)INFO: ================= client 1 received finish message =================\r\n",
      "2022-09-13 12:45:03,675 (client:453)INFO: Client #1 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030/prediction.csv\r\n",
      "2022-09-13 12:45:03,675 (monitor:121)INFO: In worker #1, the system-related metrics are: {'id': 1, 'fl_end_time_minutes': 3.66313, 'total_model_size': 304514, 'total_flops': 0, 'total_upload_bytes': 32320, 'total_download_bytes': 122496, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:03,675 (client:440)INFO: ================= client 2 received finish message =================\r\n",
      "2022-09-13 12:45:03,686 (client:453)INFO: Client #2 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030/prediction.csv\r\n",
      "2022-09-13 12:45:03,686 (monitor:121)INFO: In worker #2, the system-related metrics are: {'id': 2, 'fl_end_time_minutes': 3.663064, 'total_model_size': 278786, 'total_flops': 0, 'total_upload_bytes': 32320, 'total_download_bytes': 122496, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:03,686 (client:440)INFO: ================= client 3 received finish message =================\r\n",
      "2022-09-13 12:45:03,771 (client:453)INFO: Client #3 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030/prediction.csv\r\n",
      "2022-09-13 12:45:03,772 (monitor:121)INFO: In worker #3, the system-related metrics are: {'id': 3, 'fl_end_time_minutes': 3.664201, 'total_model_size': 497474, 'total_flops': 0, 'total_upload_bytes': 32320, 'total_download_bytes': 122496, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:03,772 (client:440)INFO: ================= client 4 received finish message =================\r\n",
      "2022-09-13 12:45:03,780 (client:453)INFO: Client #4 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030/prediction.csv\r\n",
      "2022-09-13 12:45:03,781 (monitor:121)INFO: In worker #4, the system-related metrics are: {'id': 4, 'fl_end_time_minutes': 3.664119, 'total_model_size': 111554, 'total_flops': 0, 'total_upload_bytes': 32224, 'total_download_bytes': 122496, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:03,781 (client:440)INFO: ================= client 5 received finish message =================\r\n",
      "2022-09-13 12:45:03,792 (client:453)INFO: Client #5 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030/prediction.csv\r\n",
      "2022-09-13 12:45:03,792 (monitor:121)INFO: In worker #5, the system-related metrics are: {'id': 5, 'fl_end_time_minutes': 3.664061, 'total_model_size': 253058, 'total_flops': 0, 'total_upload_bytes': 32224, 'total_download_bytes': 122496, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:03,792 (client:440)INFO: ================= client 6 received finish message =================\r\n",
      "2022-09-13 12:45:03,838 (client:453)INFO: Client #6 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030/prediction.csv\r\n",
      "2022-09-13 12:45:03,838 (monitor:121)INFO: In worker #6, the system-related metrics are: {'id': 6, 'fl_end_time_minutes': 3.664579, 'total_model_size': 304514, 'total_flops': 0, 'total_upload_bytes': 32320, 'total_download_bytes': 122496, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:03,839 (client:440)INFO: ================= client 7 received finish message =================\r\n",
      "2022-09-13 12:45:03,926 (client:453)INFO: Client #7 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030/prediction.csv\r\n",
      "2022-09-13 12:45:03,935 (monitor:121)INFO: In worker #7, the system-related metrics are: {'id': 7, 'fl_end_time_minutes': 3.665885, 'total_model_size': 510338, 'total_flops': 0, 'total_upload_bytes': 32320, 'total_download_bytes': 122496, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:03,935 (client:440)INFO: ================= client 8 received finish message =================\r\n",
      "2022-09-13 12:45:03,966 (client:453)INFO: Client #8 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030/prediction.csv\r\n",
      "2022-09-13 12:45:03,966 (monitor:121)INFO: In worker #8, the system-related metrics are: {'id': 8, 'fl_end_time_minutes': 3.666147, 'total_model_size': 265922, 'total_flops': 0, 'total_upload_bytes': 31816, 'total_download_bytes': 122496, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:03,966 (client:440)INFO: ================= client 9 received finish message =================\r\n",
      "2022-09-13 12:45:08,500 (client:453)INFO: Client #9 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030/prediction.csv\r\n",
      "2022-09-13 12:45:08,500 (monitor:121)INFO: In worker #9, the system-related metrics are: {'id': 9, 'fl_end_time_minutes': 3.741381, 'total_model_size': 381633, 'total_flops': 0, 'total_upload_bytes': 31912, 'total_download_bytes': 122496, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:08,500 (client:440)INFO: ================= client 10 received finish message =================\r\n",
      "2022-09-13 12:45:11,949 (client:453)INFO: Client #10 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030/prediction.csv\r\n",
      "2022-09-13 12:45:11,949 (monitor:121)INFO: In worker #10, the system-related metrics are: {'id': 10, 'fl_end_time_minutes': 3.798597, 'total_model_size': 99210, 'total_flops': 0, 'total_upload_bytes': 31912, 'total_download_bytes': 122496, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:11,949 (client:440)INFO: ================= client 11 received finish message =================\r\n",
      "2022-09-13 12:45:12,036 (client:453)INFO: Client #11 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030/prediction.csv\r\n",
      "2022-09-13 12:45:12,037 (monitor:121)INFO: In worker #11, the system-related metrics are: {'id': 11, 'fl_end_time_minutes': 3.799795, 'total_model_size': 304449, 'total_flops': 0, 'total_upload_bytes': 31912, 'total_download_bytes': 122496, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:12,037 (client:440)INFO: ================= client 12 received finish message =================\r\n",
      "2022-09-13 12:45:12,062 (client:453)INFO: Client #12 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030/prediction.csv\r\n",
      "2022-09-13 12:45:12,062 (monitor:121)INFO: In worker #12, the system-related metrics are: {'id': 12, 'fl_end_time_minutes': 3.799948, 'total_model_size': 304449, 'total_flops': 0, 'total_upload_bytes': 31816, 'total_download_bytes': 122496, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:12,062 (client:440)INFO: ================= client 13 received finish message =================\r\n",
      "2022-09-13 12:45:14,448 (client:453)INFO: Client #13 finished saving prediction results in /home/michael/Master thesis/Code/FederatedScope_thesis/exp/FedAvg_gin_on_cikmcup_lr0.1_lstep1_/sub_exp_20220913124030/prediction.csv\r\n",
      "2022-09-13 12:45:14,448 (monitor:121)INFO: In worker #13, the system-related metrics are: {'id': 13, 'fl_end_time_minutes': 3.839437, 'total_model_size': 163660, 'total_flops': 0, 'total_upload_bytes': 31912, 'total_download_bytes': 122496, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}\r\n",
      "2022-09-13 12:45:14,448 (monitor:278)INFO: We will compress the file eval_results.raw into a .gz file, and delete the old one\r\n",
      "2022-09-13 12:45:14,449 (monitor:195)INFO: After merging the system metrics from all works, we got avg: defaultdict(None, {'id': 'sys_avg', 'sys_avg/fl_end_time_minutes': 3.711203, 'sys_avg/total_model_size': '263.64K', 'sys_avg/total_flops': '0.0', 'sys_avg/total_upload_bytes': '140.19K', 'sys_avg/total_download_bytes': '140.11K', 'sys_avg/global_convergence_round': 0.0, 'sys_avg/local_convergence_round': 0.0, 'sys_avg/global_convergence_time_minutes': 0.0, 'sys_avg/local_convergence_time_minutes': 0.0})\r\n",
      "2022-09-13 12:45:14,449 (monitor:198)INFO: After merging the system metrics from all works, we got std: defaultdict(None, {'id': 'sys_std', 'sys_std/fl_end_time_minutes': 0.065805, 'sys_std/total_model_size': '134.51K', 'sys_std/total_flops': '0.0', 'sys_std/total_upload_bytes': '392.43K', 'sys_std/total_download_bytes': '73.87K', 'sys_std/global_convergence_round': 0.0, 'sys_std/local_convergence_round': 0.0, 'sys_std/global_convergence_time_minutes': 0.0, 'sys_std/local_convergence_time_minutes': 0.0})\r\n"
     ]
    }
   ],
   "source": [
    "!python federatedscope/main.py --cfg federatedscope/gfl/baseline/fedavg_gin_minibatch_on_cikmcup.yaml --client_cfg federatedscope/gfl/baseline/fedavg_gin_minibatch_on_cikmcup_per_client.yaml federate.total_round_num 3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}