{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import mnist_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asyn:\n",
      "  min_received_num: 2\n",
      "  min_received_rate: -1.0\n",
      "  timeout: 0\n",
      "  use: True\n",
      "attack:\n",
      "  alpha_TV: 0.001\n",
      "  alpha_prop_loss: 0\n",
      "  attack_method: \n",
      "  attacker_id: -1\n",
      "  classifier_PIA: randomforest\n",
      "  info_diff_type: l2\n",
      "  inject_round: 0\n",
      "  max_ite: 400\n",
      "  reconstruct_lr: 0.01\n",
      "  reconstruct_optim: Adam\n",
      "  target_label_ind: -1\n",
      "backend: torch\n",
      "cfg_file: \n",
      "criterion:\n",
      "  type: MSELoss\n",
      "data:\n",
      "  args: []\n",
      "  batch_size: 64\n",
      "  cSBM_phi: [0.5, 0.5, 0.5]\n",
      "  consistent_label_distribution: False\n",
      "  drop_last: False\n",
      "  graphsaint:\n",
      "    num_steps: 30\n",
      "    walk_length: 2\n",
      "  loader: \n",
      "  num_workers: 0\n",
      "  pre_transform: []\n",
      "  quadratic:\n",
      "    dim: 1\n",
      "    max_curv: 12.5\n",
      "    min_curv: 0.02\n",
      "  root: data\n",
      "  server_holds_all: False\n",
      "  shuffle: True\n",
      "  sizes: [10, 5]\n",
      "  splits: [0.8, 0.1, 0.1]\n",
      "  splitter: \n",
      "  splitter_args: []\n",
      "  subsample: 1.0\n",
      "  target_transform: []\n",
      "  transform: []\n",
      "  type: toy\n",
      "device: -1\n",
      "distribute:\n",
      "  client_host: 0.0.0.0\n",
      "  client_port: 50050\n",
      "  data_file: data\n",
      "  data_idx: -1\n",
      "  grpc_enable_http_proxy: False\n",
      "  grpc_max_receive_message_length: 104857600\n",
      "  grpc_max_send_message_length: 104857600\n",
      "  role: client\n",
      "  server_host: 0.0.0.0\n",
      "  server_port: 50050\n",
      "  use: False\n",
      "early_stop:\n",
      "  delta: 0.0\n",
      "  improve_indicator_mode: best\n",
      "  patience: 5\n",
      "  the_smaller_the_better: True\n",
      "eval:\n",
      "  best_res_update_round_wise_key: val_loss\n",
      "  count_flops: True\n",
      "  freq: 1\n",
      "  metrics: []\n",
      "  monitoring: []\n",
      "  report: ['weighted_avg', 'avg', 'fairness', 'raw']\n",
      "  save_data: False\n",
      "  split: ['test', 'val']\n",
      "expname: \n",
      "expname_tag: \n",
      "federate:\n",
      "  client_num: 0\n",
      "  data_weighted_aggr: False\n",
      "  ignore_weight: False\n",
      "  join_in_info: []\n",
      "  make_global_eval: False\n",
      "  method: FedAvg\n",
      "  mode: standalone\n",
      "  online_aggr: False\n",
      "  restore_from: \n",
      "  sample_client_num: -1\n",
      "  sample_client_rate: -1.0\n",
      "  sampler: uniform\n",
      "  save_to: \n",
      "  share_local_model: False\n",
      "  total_round_num: 50\n",
      "  unseen_clients_rate: 0.0\n",
      "  use_diff: False\n",
      "  use_ss: False\n",
      "fedopt:\n",
      "  optimizer:\n",
      "    lr: 0.01\n",
      "    type: SGD\n",
      "  use: False\n",
      "fedprox:\n",
      "  mu: 0.0\n",
      "  use: False\n",
      "fedsageplus:\n",
      "  a: 1.0\n",
      "  b: 1.0\n",
      "  c: 1.0\n",
      "  fedgen_epoch: 200\n",
      "  gen_hidden: 128\n",
      "  hide_portion: 0.5\n",
      "  loc_epoch: 1\n",
      "  num_pred: 5\n",
      "finetune:\n",
      "  batch_or_epoch: epoch\n",
      "  before_eval: False\n",
      "  freeze_param: \n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "flitplus:\n",
      "  factor_ema: 0.8\n",
      "  lambdavat: 0.5\n",
      "  tmpFed: 0.5\n",
      "  weightReg: 1.0\n",
      "gcflplus:\n",
      "  EPS_1: 0.05\n",
      "  EPS_2: 0.1\n",
      "  seq_length: 5\n",
      "  standardize: False\n",
      "grad:\n",
      "  grad_clip: -1.0\n",
      "hpo:\n",
      "  fedex:\n",
      "    cutoff: 0.0\n",
      "    diff: False\n",
      "    eta0: -1.0\n",
      "    flatten_ss: True\n",
      "    gamma: 0.0\n",
      "    num_arms: 16\n",
      "    sched: auto\n",
      "    ss: \n",
      "    use: False\n",
      "  init_cand_num: 16\n",
      "  larger_better: False\n",
      "  log_scale: False\n",
      "  metric: client_summarized_weighted_avg.val_loss\n",
      "  num_workers: 0\n",
      "  pbt:\n",
      "    max_stage: 5\n",
      "    perf_threshold: 0.1\n",
      "  plot_interval: 1\n",
      "  scheduler: rs\n",
      "  sha:\n",
      "    budgets: []\n",
      "    elim_rate: 3\n",
      "    elim_round_num: 3\n",
      "  ss: \n",
      "  table:\n",
      "    eps: 0.1\n",
      "    idx: 0\n",
      "    num: 27\n",
      "    ss: \n",
      "  working_folder: hpo\n",
      "model:\n",
      "  dropout: 0.5\n",
      "  embed_size: 8\n",
      "  graph_pooling: mean\n",
      "  hidden: 256\n",
      "  in_channels: 0\n",
      "  layer: 2\n",
      "  model_num_per_trainer: 1\n",
      "  num_item: 0\n",
      "  num_user: 0\n",
      "  out_channels: 1\n",
      "  task: node\n",
      "  type: lr\n",
      "  use_bias: True\n",
      "nbafl:\n",
      "  constant: 30.0\n",
      "  epsilon: 100.0\n",
      "  mu: 0.0\n",
      "  use: False\n",
      "  w_clip: 1.0\n",
      "outdir: exp\n",
      "personalization:\n",
      "  K: 5\n",
      "  beta: 1.0\n",
      "  local_param: []\n",
      "  local_update_steps: -1\n",
      "  lr: 0.0\n",
      "  regular_weight: 0.1\n",
      "  share_non_trainable_para: False\n",
      "print_decimal_digits: 6\n",
      "regularizer:\n",
      "  mu: 0.0\n",
      "  type: \n",
      "seed: 0\n",
      "sgdmf:\n",
      "  R: 5.0\n",
      "  constant: 1.0\n",
      "  delta: 0.5\n",
      "  epsilon: 4.0\n",
      "  theta: -1\n",
      "  use: False\n",
      "train:\n",
      "  batch_or_epoch: batch\n",
      "  local_update_steps: 1\n",
      "  optimizer:\n",
      "    lr: 0.1\n",
      "    type: SGD\n",
      "trainer:\n",
      "  type: general\n",
      "use_gpu: False\n",
      "verbose: 1\n",
      "vertical:\n",
      "  dims: [5, 10]\n",
      "  encryption: paillier\n",
      "  key_size: 3072\n",
      "  use: False\n",
      "wandb:\n",
      "  client_train_info: False\n",
      "  name_project: \n",
      "  name_user: \n",
      "  online_track: True\n",
      "  use: False\n"
     ]
    }
   ],
   "source": [
    "from federatedscope.core.configs.config import global_cfg\n",
    "\n",
    "cfg = global_cfg.clone()\n",
    "print(cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from federatedscope.core.auxiliaries.data_builder import get_data\n",
    "\n",
    "cfg.data.type = 'mydata'\n",
    "cfg.data.splits = [0.6, 0.2, 0.2]\n",
    "cfg.data.batch_size = 10\n",
    "cfg.data.subsample = 0.05\n",
    "cfg.data.transform = [['ToTensor'], ['Normalize', {'mean': [0.1307], 'std': [0.3081]}]]\n",
    "\n",
    "data, modified_cfg = get_data(cfg.clone())\n",
    "cfg.merge_from_other_cfg(modified_cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "cfg.model.type = 'mynet'\n",
    "cfg.model.out_channels = 62"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "cfg.use_gpu = True\n",
    "cfg.eval.freq = 10\n",
    "cfg.eval.metrics = ['acc', 'loss_regular']\n",
    "\n",
    "cfg.federate.mode = 'standalone'\n",
    "cfg.federate.local_update_steps = 5\n",
    "cfg.federate.total_round_num = 200\n",
    "cfg.federate.sample_client_num = 5\n",
    "cfg.federate.client_num = 10\n",
    "\n",
    "cfg.train.optimizer.lr = 0.1\n",
    "cfg.train.optimizer.weight_decay = 0.0\n",
    "cfg.grad.grad_clip = 5.0\n",
    "\n",
    "cfg.criterion.type = 'CrossEntropyLoss'\n",
    "cfg.trainer.type = 'mytrainer'\n",
    "cfg.seed = 123"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 13:44:52,423 (utils:129)INFO: the current machine is at 127.0.1.1\n",
      "2022-08-29 13:44:52,424 (utils:131)INFO: the current dir is /home/michael/Master thesis/Code/FederatedScope_thesis\n",
      "2022-08-29 13:44:52,424 (utils:132)INFO: the output dir is exp/FedAvg_mynet_on_mydata_lr0.1_lstep1_\n"
     ]
    }
   ],
   "source": [
    "from federatedscope.core.auxiliaries.utils import setup_seed, update_logger\n",
    "\n",
    "setup_seed(cfg.seed)\n",
    "update_logger(cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "CN({'backend': 'torch', 'use_gpu': True, 'verbose': 1, 'print_decimal_digits': 6, 'device': -1, 'seed': 123, 'cfg_file': '', 'outdir': 'exp/FedAvg_mynet_on_mydata_lr0.1_lstep1_', 'expname': 'FedAvg_mynet_on_mydata_lr0.1_lstep1_', 'expname_tag': '', 'hpo': CN({'working_folder': 'hpo', 'ss': '', 'num_workers': 0, 'init_cand_num': 16, 'log_scale': False, 'larger_better': False, 'scheduler': 'rs', 'plot_interval': 1, 'metric': 'client_summarized_weighted_avg.val_loss', 'sha': CN({'elim_round_num': 3, 'elim_rate': 3, 'budgets': []}), 'pbt': CN({'max_stage': 5, 'perf_threshold': 0.1}), 'fedex': CN({'use': False, 'ss': '', 'flatten_ss': True, 'eta0': -1.0, 'sched': 'auto', 'cutoff': 0.0, 'gamma': 0.0, 'num_arms': 16, 'diff': False}), 'table': CN({'ss': '', 'eps': 0.1, 'num': 27, 'idx': 0})}), 'data': CN({'root': 'data', 'type': 'mydata', 'args': [], 'splitter': '', 'splitter_args': [], 'transform': [['ToTensor'], ['Normalize', {'mean': [0.1307], 'std': [0.3081]}]], 'target_transform': [], 'pre_transform': [], 'batch_size': 10, 'drop_last': False, 'sizes': [10, 5], 'shuffle': True, 'server_holds_all': False, 'subsample': 0.05, 'splits': [0.6, 0.2, 0.2], 'consistent_label_distribution': False, 'cSBM_phi': [0.5, 0.5, 0.5], 'loader': '', 'num_workers': 0, 'graphsaint': CN({'walk_length': 2, 'num_steps': 30}), 'quadratic': CN({'dim': 1, 'min_curv': 0.02, 'max_curv': 12.5})}), 'trainer': CN({'type': 'mytrainer'}), 'train': CN({'local_update_steps': 1, 'batch_or_epoch': 'batch', 'optimizer': CN({'type': 'SGD', 'lr': 0.1, 'weight_decay': 0.0})}), 'finetune': CN({'before_eval': False, 'local_update_steps': 1, 'batch_or_epoch': 'epoch', 'freeze_param': '', 'optimizer': CN({'type': 'SGD', 'lr': 0.1})}), 'grad': CN({'grad_clip': 5.0}), 'early_stop': CN({'patience': 5, 'delta': 0.0, 'improve_indicator_mode': 'best', 'the_smaller_the_better': True}), 'eval': CN({'save_data': False, 'freq': 10, 'metrics': ['acc', 'loss_regular'], 'split': ['test', 'val'], 'report': ['weighted_avg', 'avg', 'fairness', 'raw'], 'best_res_update_round_wise_key': 'val_loss', 'monitoring': [], 'count_flops': True}), 'wandb': CN({'use': False, 'name_user': '', 'name_project': '', 'online_track': True, 'client_train_info': False}), 'model': CN({'model_num_per_trainer': 1, 'type': 'mynet', 'use_bias': True, 'task': 'node', 'hidden': 256, 'dropout': 0.5, 'in_channels': 0, 'out_channels': 62, 'layer': 2, 'graph_pooling': 'mean', 'embed_size': 8, 'num_item': 0, 'num_user': 0}), 'criterion': CN({'type': 'CrossEntropyLoss'}), 'regularizer': CN({'type': '', 'mu': 0.0}), 'asyn': CN({'use': True, 'timeout': 0, 'min_received_num': -1, 'min_received_rate': -1.0}), 'nbafl': CN({'use': False, 'mu': 0.0, 'epsilon': 100.0, 'w_clip': 1.0, 'constant': 30.0}), 'sgdmf': CN({'use': False, 'R': 5.0, 'epsilon': 4.0, 'delta': 0.5, 'constant': 1.0, 'theta': -1}), 'federate': CN({'client_num': 10, 'sample_client_num': 5, 'sample_client_rate': -1.0, 'unseen_clients_rate': 0.0, 'total_round_num': 200, 'mode': 'standalone', 'share_local_model': False, 'data_weighted_aggr': False, 'online_aggr': False, 'make_global_eval': False, 'use_diff': False, 'method': 'FedAvg', 'ignore_weight': False, 'use_ss': False, 'restore_from': '', 'save_to': '', 'join_in_info': [], 'sampler': 'uniform', 'local_update_steps': 5}), 'distribute': CN({'use': False, 'server_host': '0.0.0.0', 'server_port': 50050, 'client_host': '0.0.0.0', 'client_port': 50050, 'role': 'client', 'data_file': 'data', 'data_idx': -1, 'grpc_max_send_message_length': 104857600, 'grpc_max_receive_message_length': 104857600, 'grpc_enable_http_proxy': False}), 'vertical': CN({'use': False, 'encryption': 'paillier', 'dims': [5, 10], 'key_size': 3072}), 'attack': CN({'attack_method': '', 'target_label_ind': -1, 'attacker_id': -1, 'reconstruct_lr': 0.01, 'reconstruct_optim': 'Adam', 'info_diff_type': 'l2', 'max_ite': 400, 'alpha_TV': 0.001, 'alpha_prop_loss': 0, 'classifier_PIA': 'randomforest', 'inject_round': 0}), 'fedopt': CN({'use': False, 'optimizer': CN({'type': 'SGD', 'lr': 0.01})}), 'fedprox': CN({'use': False, 'mu': 0.0}), 'personalization': CN({'local_param': [], 'share_non_trainable_para': False, 'local_update_steps': 1, 'regular_weight': 0.1, 'lr': 0.1, 'K': 5, 'beta': 1.0}), 'fedsageplus': CN({'num_pred': 5, 'gen_hidden': 128, 'hide_portion': 0.5, 'fedgen_epoch': 200, 'loc_epoch': 1, 'a': 1.0, 'b': 1.0, 'c': 1.0}), 'gcflplus': CN({'EPS_1': 0.05, 'EPS_2': 0.1, 'seq_length': 5, 'standardize': False}), 'flitplus': CN({'tmpFed': 0.5, 'lambdavat': 0.5, 'factor_ema': 0.8, 'weightReg': 1.0})})"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "federatedscope.core.worker.server.Server"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from federatedscope.core.fed_runner import FedRunner\n",
    "from federatedscope.core.auxiliaries.worker_builder import get_server_cls, get_client_cls\n",
    "get_server_cls(cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m Fed_runner \u001B[38;5;241m=\u001B[39m \u001B[43mFedRunner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mserver_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mget_server_cls\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mclient_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mget_client_cls\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m Fed_runner\u001B[38;5;241m.\u001B[39mrun()\n",
      "File \u001B[0;32m~/Master thesis/Code/FederatedScope_thesis/federatedscope/core/fed_runner.py:58\u001B[0m, in \u001B[0;36mFedRunner.__init__\u001B[0;34m(self, data, server_class, client_class, config, client_config)\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstandalone\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshared_comm_queue \u001B[38;5;241m=\u001B[39m deque()\n\u001B[0;32m---> 58\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setup_for_standalone\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;66;03m# in standalone mode, by default, we print the trainer info only\u001B[39;00m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;66;03m# once for better logs readability\u001B[39;00m\n\u001B[1;32m     61\u001B[0m     trainer_representative \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mtrainer\n",
      "File \u001B[0;32m~/Master thesis/Code/FederatedScope_thesis/federatedscope/core/fed_runner.py:104\u001B[0m, in \u001B[0;36mFedRunner._setup_for_standalone\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    101\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mfederate\u001B[38;5;241m.\u001B[39msample_client_num \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    102\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mfreeze()\n\u001B[0;32m--> 104\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_setup_server\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclient \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m()\n\u001B[1;32m    108\u001B[0m \u001B[38;5;66;03m# assume the client-wise data are consistent in their input&output\u001B[39;00m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;66;03m# shape\u001B[39;00m\n",
      "File \u001B[0;32m~/Master thesis/Code/FederatedScope_thesis/federatedscope/core/fed_runner.py:206\u001B[0m, in \u001B[0;36mFedRunner._setup_server\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstandalone\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 206\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mserver_id\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m:\n\u001B[1;32m    207\u001B[0m         server_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mserver_id]\n\u001B[1;32m    208\u001B[0m         model \u001B[38;5;241m=\u001B[39m get_model(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mmodel,\n\u001B[1;32m    209\u001B[0m                           server_data,\n\u001B[1;32m    210\u001B[0m                           backend\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcfg\u001B[38;5;241m.\u001B[39mbackend)\n",
      "\u001B[0;31mTypeError\u001B[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "Fed_runner = FedRunner(data=data,\n",
    "                       server_class=get_server_cls(cfg),\n",
    "                       client_class=get_client_cls(cfg),\n",
    "                       config=cfg.clone())\n",
    "Fed_runner.run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'NVIDIA GeForce RTX 3060 Laptop GPU'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}